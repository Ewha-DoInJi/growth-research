# Team-Info
| (1) 과제명 | Quantization based on Layer-wise Activation Analysis in Stable Diffusion Models
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 23-이화도인지 |
| (3) 팀 구성원 | 김도은 (2076035): 리더, *연구 및 논문 작성* <br> 박인애 (2171088): 팀원, *연구 및 논문 작성* <br> 변지은 (2076193) : 팀원, *연구 및 논문 작성*			 |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 팀 멘토 | 박준석 멘토님 / 삼성전자 / 수석 연구원 |
| (6) 과제 분류 | 연구 과제 |
| (6) 과제 키워드 | Diffusion model, Quantization, XAI  |
| (7) 과제 내용 요약 | 본 연구는 diffusion model이 timestep마다 서로 다른 layer를 활성화된다는 가설을 기반으로 진행되었습니다. MNIST 데이터셋을 사용하여 기본 diffusion 모델인 DDPM을 1,000 timestep 동안 학습시키고, 각 timestep에서 활성화된 layer를 분석하기 위해 Fisher information 값을 추출하여 활성화 양상을 평가합니다.<br><br>연구의 주요 목표는 diffusion model의 높은 inference time 문제를 개선하는 것입니다. 이를 위해 U-Net 구조에 quantization을 도입하여 연산 속도를 단축하고자 하며, Fisher information 분석 결과를 바탕으로 timestep별 활성화된 layer에 집중적으로 양자화를 적용하는 방식으로 문제를 해결할 계획입니다. 먼저 U-net을 6개 layer로 구분한 후에 각 파트별로 fisher information value 로 timestep마다 활성화되는 layer 및 layer 내의 weight 를 파악합니다. 이와 함께, 정량적 비교를 위해 log scale과 minmax 정규화 기법을 활용하여 정확한 분석을 수행했습니다. 연구 결과, 각 layer의 앞부분 weight가 전반적으로 큰 기여도를 가지며, timestep에 따른 weight 분포의 변화를 살펴본 결과, 초기 timestep에서는 layer의 앞부분 weight 기여도가 높고, 후반 timestep에서는 layer의 뒷부분 weight 기여도가 높아지는 경향을 발견하였습니다. 기존의 전체 layer 동일하게 quantization을 적용하는 방식이 아닌 layer 별로 맞춤형 quantization을 적용함으로써 모델의 속도를 높이되 quantization으로 인한 손실을 최소화하는 성과를 목표로 합니다.<br><br>Quantization 과정에서는 float형 비트 수 감소와 int형 변환을 통해 연산 효율성을 개선합니다. 본 연구는 diffusion model에 XAI 기법을 적용한 새로운 분석 방법을 제시하며, 제안된 quantization 기법이 inference 속도 향상에 기여할 것으로 기대됩니다.|
| (8) 주요 Link | 과제 GIT Address: https://github.com/Ewha-DoInJi/growth-research <br> 과제 보고서: https://github.com/Ewha-DoInJi/growth-research/blob/main/reports/23-이화도인지-1차보고서-v1.md|
| (10) 기타 |  |
<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | Stable Diffusion을 비롯한 현대 이미지 생성형 AI의 주류인 Diffusion 모델은 time step마다 노이즈를 제거하는 과정을 통해 이미지를 생성하는 방식을 채택하고 있습니다. 이 방법은 이미지의 다양성을 높이는 장점이 있지만, 동시에 전체 생성 시간이 길어지는 문제를 안고 있습니다. 이러한 문제는 실시간 응용이나 대규모 이미지 생성 작업에서 주요한 제약 요인으로 작용하며, 성능을 개선하려는 노력이 지속되고 있습니다. Diffusion 모델은 AI 연구자 및 개발자들에게 큰 수혜를 제공할 수 있는 잠재적 기술로 평가받고 있습니다. <br> 저희 팀은 LDM-4를 기반으로 한 PTQD: Accurate Post-Training Quantization for Diffusion Models (NeurIPS 2023) 논문을 벤치마킹하고 있습니다. 이 논문에서의 실험 설정을 따라 200 time step과 250 time step의 설정으로 코드를 재현해본 결과, 양자화를 적용하지 않은 Diffusion 모델에서는 250 time step 기준으로 13초, 200 time step 기준으로 8초가 소요되었습니다. <br> ![image1](https://github.com/user-attachments/assets/0395ddaa-8899-4ee0-9cc5-3ffa6c8ba7f5) <br> ![image2](https://github.com/user-attachments/assets/3df41fdb-f172-4974-8712-a87a3fdb9558) <br> Diffusion 모델은 기존 이미지 생성형 AI의 주류였던 GAN 모델과 비교했을 때, 추론 속도가 느리다는 단점이 있습니다. 이로 인해 Diffusion 모델의 장점을 살리면서도 GAN과 유사한 추론 속도를 목표로 하는 연구가 활발히 진행되고 있습니다. 대표적인 예로 "Diffusion Models Beat GANs on Image Synthesis" (NeurIPS 2021) 논문에서 Diffusion 모델이 이미지 생성 품질에서 GAN을 능가하지만, 속도는 여전히 개선이 필요한 부분으로 지적되고 있습니다. <br> 이와 같은 배경에서 Diffusion 모델의 속도 문제를 해결하고자 양자화 및 최적화 방법을 적용하는 연구는 매우 중요한 주제로 떠오르고 있습니다.|
| (2) 기존 연구와의 비교 | Diffusion 모델에 Quantization을 적용하여 추론 속도를 향상시키는 기존 연구는 다음과 같습니다. 선행 연구 논문은 지도교수님의 추천과 해외 Top-tier 학회 논문을 기준으로 선정되었습니다. <br><br> 1. [Q-Diffusion: Quantizing Diffusion Models (ICCV 2023)](https://arxiv.org/abs/2302.04304) <br> 2. [PTQD: Accurate Post-Training Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2305.10657) <br> 3. [Temporal Dynamic Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2306.02316) <br><br> 위의 세 논문은 모두 재학습이 필요 없는 Post-Training Quantization (PTQ) 방식을 사용하여 Diffusion 모델의 다중 time step 특성에 맞춘 양자화 기법을 제시하고 있습니다. Quantization 과정에서 발생하는 오류 축적 문제를 노이즈 관리 및 variance 조정 등의 방법을 통해 해결하고 있으며, 모델의 성능은 FID 점수와 추론 속도로 평가합니다. FID 점수는 낮을수록 좋은 성능을 나타냅니다. <br> 저희 팀이 벤치마킹하고 있는 논문(PTQD)에서는 FID 점수가 0.06만 증가하고, 비트 연산량을 19.9배 감소시키는 성과를 기록했습니다. 또한, 세 논문 모두 Time Step별로 다른 양자화 전략을 적용해 성능을 향상시키는 방식을 채택하고 있습니다.<br> 위 세 논문 모두 Diffusion Model 위에 Quantization 을 적용하여 유의미한 성능을 거두었지만, 저희 연구는 기존 연구의 Time Step별 양자화 방식을 채택하여 설명가능한(XAI)을 도입해 layer별로 다른 양자화 기법을 적용하는 방식으로 차별점을 두고자 합니다. 이를 통해 양자화 시 발생하는 오류를 줄이고, 모델의 성능과 효율성을 극대화하는 것이 목표입니다. |
| (3) 제안 내용 | 본 연구의 목표는 Stable Diffusion 모델의 추론 속도를 개선하면서도 이미지 품질 저하를 최소화하는 데 있습니다. 모델의 추론 속도 향상을 위해 흔히 사용되는 방법 중 하나는 양자화입니다. 그러나 양자화는 필연적으로 정보 손실을 초래하여 이미지 품질 저하를 야기할 수 있습니다. 이를 해결하기 위하여, 본 연구는 모델 전체에 일률적으로 양자화를 적용하는 대신, 이미지 품질에 상대적으로 낮은 기여도를 보이는 부분에는 보다 강하게 양자화를 적용하고, 이미지 품질에 높은 기여도를 보이는 부분에는 양자화 강도를 줄이는 접근법을 제안합니다. 이러한 차별화된 양자화 적용 방식을 통해 정보 손실을 최소화함으로써 추론 속도의 향상과 동시에 이미지 품질 저하를 최소화할 수 있을 것으로 기대됩니다. <br><br> 본 연구는 diffusion model이 이미지를 생성하는 과정에서 timestep에 따라 layer별 활성화 정도가 달라질 것이라는 가설을 바탕으로 진행되었습니다. 이를 확인하기 위해 timestep에 따른 layer별 활성화 정도를 layer의 weight 값을 비교 분석하여 평가하였습니다. 분석 방법으로는 weight magnitude map의 시각화와 XAI 기법 중 하나인 Fisher Information matrix를 활용한 시각화를 사용하였습니다. 실험 결과를 기반으로 weight의 threshold 값을 설정하였으며, threshold 값보다 작은 weight 값을 가지는 경우에는 양자화를 적용하고, 큰 값을 가지는 경우에는 양자화를 적용하지 않는 부분 양자화 방식을 제안하였습니다. 이를 통해 연산 속도 향상과 이미지 품질 유지 사이의 최적점을 도출하고자 합니다. |
| (4) 기대효과 및 의의 | 제안된 방법을 통해 다음과 같은 효과를 기대할 수 있습니다: <br> 1. 연산 속도의 향상: 선택적 양자화를 통해 전체적인 이미지 생성 시간을 단축할 수 있습니다. <br> 2. 이미지 품질 유지: 중요 레이어의 정밀도를 보존함으로써 기존 양자화 방식 대비 우수한 이미지 품질을 유지할 수 있습니다. <br> 3. 모델 해석 가능성 향상: XAI 기법의 활용을 통해 모델의 동작 원리에 대한 이해를 증진시킬 수 있습니다. |
| (5) 주요 기능 리스트 | Fisher Information Matrix, Weight magnitude map, Simple Diffusion model, PTQD, Latent Diffusion Model |

<br>
 
# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 |  |
| (2) 전체 시스템 구성 | ![ewhadoinji-system-architecture](https://github.com/user-attachments/assets/59d59789-9c17-4e93-bbf1-90cb09d90f83) <br> - 첫 번째 단계(파란색): XAI 적용 및 공통점 분석 단계 <br> - 두 번째 단계(핑크색): 양자화 적용 단계 <br><br> 본 연구의 베이스 모델인 Latent Diffusion Model(LDM)은 NeurIPS 2023에서 발표된 [PTQD 논문](https://github.com/ziplab/PTQD)에서 제공된 코드를 활용하여 구현되었습니다.<br><br> 첫째, XAI 방법론을 활용한 분석 단계에서는 Feature Heatmap, Saliency Map, Layer-LRP, Grad-CAM 등의 기법을 사용하여 각 레이어의 활성화 패턴을 분석합니다. Feature heatmap은 직접 구현하였으며, 나머지 XAI 기법은 Captum 라이브러리를 사용하여 모델에 맞게 fine-tuning하였습니다. <br><br> 둘째, 첫 번째 단계에서 도출된 레이어 특성을 기반으로, timestep 별 양자화를 적용하는 단계입니다. 본 연구에서는 사전 학습된 모델을 활용한 양자화 방식인 PTQ(Post-Training Quantization)를 채택하였습니다. PTQ 코드 또한 [PTQD 논문](https://github.com/ziplab/PTQD)에서 제공된 Quantization 코드를 바탕으로 fine-tuning할 예정입니다. |
| (3) 주요엔진 및 기능 설계 | 기존에는 Latent Diffusion Model(LDM)과 해당 모델을 제안한 [PTQD 논문](https://github.com/ziplab/PTQD)에서 제공한 코드를 바탕으로 실험을 진행하였으나, 오류가 많고 디버깅이 어렵다는 문제점이 있었습니다. 이에 따라, [다음의 글](https://towardsdatascience.com/diffusion-model-from-scratch-in-pytorch-ddpm-9d9760528946)을 참고하여 비교적 구조가 간단한 Simple Diffusion model을 다시 구현하였으며, 해당 모델로 새로운 실험을 진행하였습니다. 기존에는 Saliency map, Layer-LRP, Grad-CAM 등의 다양한 XAI 기법을 활용하여 activation 값과 weight 값의 변화를 통해 layer 활성화도 분석을 진행하였으나, 모델의 안정성과 일괄 적용의 용이성을 고려하여 학습 과정에서 고정된 파라미터인 weight 값을 분석하는 방법으로 수정하였습니다. 이에 따라, Simple diffusion model이 이미지 생성 시 timestepd에 따른 Layer별 weight 값을 분석하였습니다. 실험은 MNIST 데이터셋을 사용하였으며 timestep 1000, 구간(per) 50으로 설정하여 진행되었습니다. 실험 결과는 다음과 같습니다.  <br><br> **1) Layer별 timestep에 따른 weight값 결과** <br> <img width="600" alt="Fisher Information Map per Layers (w:o log scale)" src="https://github.com/user-attachments/assets/de16eda0-e1fc-40d2-896f-6d0925f718ca"> <br> timestep에 따라 유의미한 weight 값의 변화를 보인 것은 Layer 1과 Layer 2 였습니다. 다만 위의 실험결과는 Layer 1과 2가 압도적으로 큰 weight 값을 가지기 때문에 작은 값을 가지는 Layer 3, 4, 5, 6의 값이 0에 수렴하는 형태로 출력되어, log scale을 적용하여 정규화하였습니다. <br><br> <img width="600" alt="Fisher Information Map per Layers (w: log scale)" src="https://github.com/user-attachments/assets/e05c5093-bbc8-47f5-adcc-22a3898cec2a"> <br> 위는 log scale 정규화를 적용한 결과 이미지입니다. 위의 결과 이미지에서도 Layer 1, 2, 6이 비교적 높은 기여도를 가짐을 알 수 있습니다. 또한, Layer 에 구분 없이 전반적으로 weight값의 변화 양상이 유사함을 확인하였습니다. <br><br> **2-1) timestep에 따른 서브모듈별 weight 값** <br> ![fisher_information_grid](https://github.com/user-attachments/assets/85597e1d-7c23-44b5-8448-012d9a4c57c7) <br><br> x축: timestep / y축: weight 값 <br><br> 모든 레이어에서 초반부에 높은 weight 값을, 후반부에서 낮은 weight 값을 가지는 경향성이 확인되었으며, 1)의 실험결과에서 확인한 바와 같이 Layer 1, 2, 6이 비교적 높은 기여도를 갖는 것을 확인할 수 있습니다. <br><br> **2-2) 서브모듈 별 weight 값** <br> (주의: timestep progression이 1.0인 상태(노란색)가 완전한 노이즈 이미지 상태이고, 0.0인 상태가 완성된 이미지 상태에 해당합니다.) <br> ![fisher_information_value_final_gradation](https://github.com/user-attachments/assets/3b7390ff-7524-48da-9b00-7e0900337120) <br> x축: 특정 Layer(Layer 1, 2, ..., 6)에 속한 서브모듈 종류 / y값: weight 값 <br><br> 2-1)의 실험 결과와 같이, Layer 1, 2, 6에 비하여 Layer 3, 4, 5의 weight 기여도가 매우 낮은 것을 확인할 수 있었습니다. 이는 plot 상으로는 유사해보이지만, y축의 값을 보면 weight 값의 차이를 확인할 수 있습니다. 해당 실험 결과를 통해서는 timestep이 1.0에서 0.0으로 진행되는 과정에서 weight 값이 반전되는 구간이 관찰되었습니다. Layer 1의 경우, 완성 이미지에 가까워지는 time step 일수록(0.0에 가까워질수록) ResBlock2.conv2 모듈과 conv 모듈의 weight 기여도가 커지는 것을 확인할 수 있었습니다. Layer 2의 경우 , 완성 이미지에 가까워지는 time step 일수록(0.0에 가까워질수록) ResBlock2.gnorm1, ResBlock2.gnorm2, ResBlock2.conv1, ResBlock2.conv2 의 weight 기여도가 커지는 것을 확인하였으며, 반면에 conv, attention_layer.proj1, attention_layer.proj2 모듈의 weight 기여도는 낮아지는 것을 확인할 수 있었습니다. Layer 6의 경우에도, 완성 이미지에 가까워지는 time step 일수록(0.0에 가까워질수록) ResBlock2.gnorm1, ResBlock2.gnorm2, ResBlock2.conv1, ResBlock2.conv2 의 weight 기여도가 커지는 것을 확인하였으며, 반면에 conv, attention_layer.proj1, attention_layer.proj2 모듈의 weight 기여도는 낮아지는 것을 확인할 수 있었습니다. <br><br> weight 값이 반전되는 구간의 정확한 timestep 파악을 위하여 timestep legend를 추가하여 시각화한 결과 이미지는 다음과 같습니다. <br> ![fisher_information_value_final_legend](https://github.com/user-attachments/assets/0405c207-9d47-4f4f-976c-0721eaa52751) <br><br> 위의 시각화 결과를 토대로, Layer 1에서는 timestep 200 부근에서, Layer 2에서는 timestep 600 부근에서, Layer 3에서는 timestep 550 부근에서, Layer 6에서는 timestep 500 부근에서 weight 값이 반전된다는 것을 확인할 수 있었습니다. <br><br><br><br> 
| (4) 주요 기능의 구현 |  |
| (5) 기타 | 11월 내에 진행되는 학회 및 공모전을 탐색 중에 있으며, 만약 있다면 참가할 예정입니다. |

<br>
