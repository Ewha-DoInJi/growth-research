# Team-Info
| (1) 과제명 | Quantization based on Layer-wise Activation Analysis in Stable Diffusion Models
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 23-이화도인지 |
| (3) 팀 구성원 | 김도은 (2076035): 리더, *연구 및 논문 작성* <br> 박인애 (2171088): 팀원, *연구 및 논문 작성* <br> 변지은 (2076193) : 팀원, *연구 및 논문 작성*			 |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 팀 멘토 | 박준석 멘토님 / 삼성전자 / 수석 연구원 |
| (6) 과제 분류 | 연구 과제 |
| (6) 과제 키워드 | Diffusion model, Quantization, XAI  |
| (7) 과제 내용 요약 | 본 연구는 diffusion model이 timestep마다 서로 다른 layer를 활성화된다는 가설을 기반으로 진행되었습니다. MNIST 데이터셋을 사용하여 기본 diffusion 모델인 DDPM을 1,000 timestep 동안 학습시키고, 각 timestep에서 활성화된 layer를 분석하기 위해 Fisher information 값을 추출하여 활성화 양상을 평가합니다.<br><br>연구의 주요 목표는 diffusion model의 높은 inference time 문제를 개선하는 것입니다. 이를 위해 U-Net 구조에 quantization을 도입하여 연산 속도를 단축하고자 하며, Fisher information 분석 결과를 바탕으로 timestep별 활성화된 layer에 집중적으로 양자화를 적용하는 방식으로 문제를 해결할 계획입니다. 먼저 U-net을 6개 layer로 구분한 후에 각 파트별로 fisher information value 로 timestep마다 활성화되는 layer 및 layer 내의 weight 를 파악합니다. 이와 함께, 정량적 비교를 위해 log scale과 minmax 정규화 기법을 활용하여 정확한 분석을 수행했습니다. 연구 결과, 각 layer의 앞부분 weight가 전반적으로 큰 기여도를 가지며, timestep에 따른 weight 분포의 변화를 살펴본 결과, 초기 timestep에서는 layer의 앞부분 weight 기여도가 높고, 후반 timestep에서는 layer의 뒷부분 weight 기여도가 높아지는 경향을 발견하였습니다. 기존의 전체 layer 동일하게 quantization을 적용하는 방식이 아닌 layer 별로 맞춤형 quantization을 적용함으로써 모델의 속도를 높이되 quantization으로 인한 손실을 최소화하는 성과를 목표로 합니다.<br><br>Quantization 과정에서는 float형 비트 수 감소와 int형 변환을 통해 연산 효율성을 개선합니다. 본 연구는 diffusion model에 XAI 기법을 적용한 새로운 분석 방법을 제시하며, 제안된 quantization 기법이 inference 속도 향상에 기여할 것으로 기대됩니다.|
| (8) 주요 Link | 과제 GIT Address: https://github.com/Ewha-DoInJi/growth-research <br> 과제 보고서: https://github.com/Ewha-DoInJi/growth-research/blob/main/reports/23-이화도인지-1차보고서-v1.md|
| (10) 기타 |  |
<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | Stable Diffusion을 비롯한 현대 이미지 생성형 AI의 주류인 Diffusion 모델은 time step마다 노이즈를 제거하는 과정을 통해 이미지를 생성하는 방식을 채택하고 있습니다. 이 방법은 이미지의 다양성을 높이는 장점이 있지만, 동시에 전체 생성 시간이 길어지는 문제를 안고 있습니다. 이러한 문제는 실시간 응용이나 대규모 이미지 생성 작업에서 주요한 제약 요인으로 작용하며, 성능을 개선하려는 노력이 지속되고 있습니다. Diffusion 모델은 AI 연구자 및 개발자들에게 큰 수혜를 제공할 수 있는 잠재적 기술로 평가받고 있습니다. <br> 저희 팀은 LDM-4를 기반으로 한 PTQD: Accurate Post-Training Quantization for Diffusion Models (NeurIPS 2023) 논문을 벤치마킹하고 있습니다. 이 논문에서의 실험 설정을 따라 200 time step과 250 time step의 설정으로 코드를 재현해본 결과, 양자화를 적용하지 않은 Diffusion 모델에서는 250 time step 기준으로 13초, 200 time step 기준으로 8초가 소요되었습니다. <br> ![image1](https://github.com/user-attachments/assets/0395ddaa-8899-4ee0-9cc5-3ffa6c8ba7f5) <br> ![image2](https://github.com/user-attachments/assets/3df41fdb-f172-4974-8712-a87a3fdb9558) <br> Diffusion 모델은 기존 이미지 생성형 AI의 주류였던 GAN 모델과 비교했을 때, 추론 속도가 느리다는 단점이 있습니다. 이로 인해 Diffusion 모델의 장점을 살리면서도 GAN과 유사한 추론 속도를 목표로 하는 연구가 활발히 진행되고 있습니다. 대표적인 예로 "Diffusion Models Beat GANs on Image Synthesis" (NeurIPS 2021) 논문에서 Diffusion 모델이 이미지 생성 품질에서 GAN을 능가하지만, 속도는 여전히 개선이 필요한 부분으로 지적되고 있습니다. <br> 이와 같은 배경에서 Diffusion 모델의 속도 문제를 해결하고자 양자화 및 최적화 방법을 적용하는 연구는 매우 중요한 주제로 떠오르고 있습니다.|
| (2) 기존 연구와의 비교 | Diffusion 모델에 Quantization을 적용하여 추론 속도를 향상시키는 기존 연구는 다음과 같습니다. 선행 연구 논문은 지도교수님의 추천과 해외 Top-tier 학회 논문을 기준으로 선정되었습니다. <br><br> 1. [Q-Diffusion: Quantizing Diffusion Models (ICCV 2023)](https://arxiv.org/abs/2302.04304) <br> 2. [PTQD: Accurate Post-Training Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2305.10657) <br> 3. [Temporal Dynamic Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2306.02316) <br><br> 위의 세 논문은 모두 재학습이 필요 없는 Post-Training Quantization (PTQ) 방식을 사용하여 Diffusion 모델의 다중 time step 특성에 맞춘 양자화 기법을 제시하고 있습니다. Quantization 과정에서 발생하는 오류 축적 문제를 노이즈 관리 및 variance 조정 등의 방법을 통해 해결하고 있으며, 모델의 성능은 FID 점수와 추론 속도로 평가합니다. FID 점수는 낮을수록 좋은 성능을 나타냅니다. <br> 저희 팀이 벤치마킹하고 있는 논문(PTQD)에서는 FID 점수가 0.06만 증가하고, 비트 연산량을 19.9배 감소시키는 성과를 기록했습니다. 또한, 세 논문 모두 Time Step별로 다른 양자화 전략을 적용해 성능을 향상시키는 방식을 채택하고 있습니다.<br> 위 세 논문 모두 Diffusion Model 위에 Quantization 을 적용하여 유의미한 성능을 거두었지만, 저희 연구는 기존 연구의 Time Step별 양자화 방식을 채택하여 설명가능한(XAI)을 도입해 layer별로 다른 양자화 기법을 적용하는 방식으로 차별점을 두고자 합니다. 이를 통해 양자화 시 발생하는 오류를 줄이고, 모델의 성능과 효율성을 극대화하는 것이 목표입니다. |
| (3) 제안 내용 | 본 연구에서는 Stable Diffusion 모델의 속도를 개선하되 이미지 품질 저하를 최소화하는 것을 목표로 하고 있습니다. 먼저 모델의 속도를 개선하려면 양자화가 필요합니다. 하지만 양자화를 적용하면 이미지 품질 저하 현상이 발생합니다. 이러한 현상을 최대한 막고자 XAI(설명 가능한 인공지능) 기법을 활용하여 모델의 특성을 파악하고 연구한 후에 연구 인사이트를 토대로 custom 양자화를 진행하고자 합니다. <br><br> 구체적으로, 각 timestep에서 활성화되는 레이어를 분석하고, 그 활성화 정도에 따라 선택적으로 양자화를 적용하는 방법을 제안합니다. 이를 통해 연산 속도의 향상과 이미지 품질 유지 사이의 최적점을 찾고자 합니다. |
| (4) 기대효과 및 의의 | 제안된 방법을 통해 다음과 같은 효과를 기대할 수 있습니다: <br> 1. 연산 속도의 향상: 선택적 양자화를 통해 전체적인 이미지 생성 시간을 단축할 수 있습니다. <br> 2. 이미지 품질 유지: 중요 레이어의 정밀도를 보존함으로써 기존 양자화 방식 대비 우수한 이미지 품질을 유지할 수 있습니다. <br> 3. 모델 해석 가능성 향상: XAI 기법의 활용을 통해 모델의 동작 원리에 대한 이해를 증진시킬 수 있습니다. |
| (5) 주요 기능 리스트 | Saliency map, Fisher Information Matrix, PTQD, Latent Diffusion Model |

<br>
 
# Project-Design
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | 본 연구의 목적을 달성하기 위해서는 크게 두 가지 단계가 필요합니다. <br><br> 첫째, XAI 기법을 적용하여 timestep별로 활성화되는 픽셀 및 레이어, 그리고 그 중요도를 분석하는 단계입니다. 기존 양자화 기법은 모델 전반에 걸쳐 동일한 수준으로 양자화를 적용함에 따라 이미지 품질 저하 문제가 발생할 수 있습니다. 이를 해결하기 위해, 본 연구에서는 timestep별로 중요한 부분에 차별적으로 양자화를 적용하는 방식을 제안합니다. 이를 위해 각 timestep에서 어떤 레이어에 양자화를 적용할지 결정해야 하므로 XAI 기법을 통해 레이어의 활성화도 및 중요도를 분석하는 것이 선행되어야 합니다. 구체적으로 특정 timestep에서 이미지 생성에 있어 가장 중요한 역할을 하는 레이어를 식별하고, timestep의 진행에 따라 레이어 활성화도 변화 양상을 분석합니다. <br><br> 둘째, 양자화 적용 단계입니다. 첫 번째 단계에서 도출된 분석 결과를 기반으로 PTQ(Post-Training Quantization)를 적용합니다. 각 timestep에서 가장 활성화되는 레이어에만 집중적으로 양자화를 적용하여 이미지 품질 저하를 개선하고자 합니다. 특히 LDM 모델의 핵심 구성요소인 U-Net에서 이루어지는 반복적 연산은 모델의 추론 속도에 중요한 영향을 미치기 때문에, U-Net 구조에 양자화를 적용할 예정입니다. |
| (2) 전체 시스템 구성 | ![ewhadoinji-system-architecture](https://github.com/user-attachments/assets/59d59789-9c17-4e93-bbf1-90cb09d90f83) <br> - 첫 번째 단계(파란색): XAI 적용 및 공통점 분석 단계 <br> - 두 번째 단계(핑크색): 양자화 적용 단계 <br><br> 본 연구의 베이스 모델인 Latent Diffusion Model(LDM)은 NeurIPS 2023에서 발표된 [PTQD 논문](https://github.com/ziplab/PTQD)에서 제공된 코드를 활용하여 구현되었습니다.<br><br> 첫째, XAI 방법론을 활용한 분석 단계에서는 Feature Heatmap, Saliency Map, Layer-LRP, Grad-CAM 등의 기법을 사용하여 각 레이어의 활성화 패턴을 분석합니다. Feature heatmap은 직접 구현하였으며, 나머지 XAI 기법은 Captum 라이브러리를 사용하여 모델에 맞게 fine-tuning하였습니다. <br><br> 둘째, 첫 번째 단계에서 도출된 레이어 특성을 기반으로, timestep 별 양자화를 적용하는 단계입니다. 본 연구에서는 사전 학습된 모델을 활용한 양자화 방식인 PTQ(Post-Training Quantization)를 채택하였습니다. PTQ 코드 또한 [PTQD 논문](https://github.com/ziplab/PTQD)에서 제공된 Quantization 코드를 바탕으로 fine-tuning할 예정입니다. |
| (3) 진척도 및 검증내역 | Diffusion Model에 XAI 기법을 적용하여 각 layer 마다 activation map을 추출하고, 클래스 별 공통점을 파악하였습니다.<br><br> 아래 사진과 같이 서로 다른 클래스(281, 283, 284)에서  layer별로, time step별로 공통된 패턴을 보임을 확인하였고, 이를 토대로 밝은 픽셀은 살리고, 어두운 픽셀은 양자화를 많이 적용하는 것을 목표로 합니다. 이러한 연구 결과를 토대로 모든 클래스에 대해 general하게 custom 양자화를 적용할 수 있다는 가능성을 보았습니다. <br><br> ![feature-map](https://github.com/user-attachments/assets/b9304abd-0683-4ff3-b1e4-daa46057bdad) <br> 다음은 Latent Diffusion Model에 양자화를 적용하기 전, 후에 생성한 이미지입니다. 기존 float-32에서 int 8로 activation map에 공통된 양자화를 적용하여 품질이 많이 낮아짐을 확인할 수 있었습니다. 저희가 위에서 발견한 인사이트를 이용하여 custom 양자화를 적용한다면 품질을 최대한 보존할 수 있음을 가설을 세웠습니다. <br><br> <img width="621" alt="quant-before-after" src="https://github.com/user-attachments/assets/78fa5fcd-91f5-4f9b-b1fe-1b0d9e20cf3b"> <br><br> 양자화를 적용하기 전에 정량적 데이터를 추출하고자 히스토그램으로 activation map의 range를 추출한 결과는 다음과 같습니다. 이 역시 서로 다른 클래스지만 layer 별로, time step 별로 공통된 분산 그래프를 띄고 있어서 동일한 min, max threshold를 이용한 양자화의 가능성을 확인하였습니다. <br> ![histogram](https://github.com/user-attachments/assets/a6ba3bd1-04d5-4e7c-b516-b6f69e8959f7)|
| (4) 기타 | 10월 중순에 학회 참가 예정입니다. |

<br>
