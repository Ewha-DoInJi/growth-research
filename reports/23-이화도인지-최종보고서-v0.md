# Team-Info
| (1) 과제명 | Quantization based on Layer-wise Activation Analysis in Stable Diffusion Models
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 23-이화도인지 |
| (3) 팀 구성원 | 김도은 (2076035): 리더, *연구 및 논문 작성* <br> 박인애 (2171088): 팀원, *연구 및 논문 작성* <br> 변지은 (2076193) : 팀원, *연구 및 논문 작성*			 |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 팀 멘토 | 박준석 멘토님 / 삼성전자 / 수석 연구원 |
| (6) 과제 분류 | 연구 과제 |
| (6) 과제 키워드 | Diffusion model, Quantization, XAI  |
| (7) 과제 내용 요약 | 본 연구는 diffusion model이 timestep마다 서로 다른 layer를 활성화된다는 가설을 기반으로 진행되었습니다. MNIST 데이터셋을 사용하여 기본 diffusion 모델인 DDPM을 1,000 timestep 동안 학습시키고, 각 timestep에서 활성화된 layer를 분석하기 위해 Fisher information 값을 추출하여 활성화 양상을 평가합니다.<br><br>연구의 주요 목표는 diffusion model의 높은 inference time 문제를 개선하는 것입니다. 이를 위해 U-Net 구조에 quantization을 도입하여 연산 속도를 단축하고자 하며, Fisher information 분석 결과를 바탕으로 timestep별 활성화된 layer에 집중적으로 양자화를 적용하는 방식으로 문제를 해결할 계획입니다. 먼저 U-net을 6개 layer로 구분한 후에 각 파트별로 fisher information value 로 timestep마다 활성화되는 layer 및 layer 내의 weight 를 파악합니다. 이와 함께, 정량적 비교를 위해 log scale과 minmax 정규화 기법을 활용하여 정확한 분석을 수행했습니다. 연구 결과, 각 layer의 앞부분 weight가 전반적으로 큰 기여도를 가지며, timestep에 따른 weight 분포의 변화를 살펴본 결과, 초기 timestep에서는 layer의 앞부분 weight 기여도가 높고, 후반 timestep에서는 layer의 뒷부분 weight 기여도가 높아지는 경향을 발견하였습니다. 기존의 전체 layer 동일하게 quantization을 적용하는 방식이 아닌 layer 별로 맞춤형 quantization을 적용함으로써 모델의 속도를 높이되 quantization으로 인한 손실을 최소화하는 성과를 목표로 합니다.<br><br>Quantization 과정에서는 float형 비트 수 감소와 int형 변환을 통해 연산 효율성을 개선합니다. 본 연구는 diffusion model에 XAI 기법을 적용한 새로운 분석 방법을 제시하며, 제안된 quantization 기법이 inference 속도 향상에 기여할 것으로 기대됩니다.|
| (8) 주요 Link | 과제 GIT Address: https://github.com/Ewha-DoInJi/growth-research <br> 과제 보고서: https://github.com/Ewha-DoInJi/growth-research/blob/main/reports/23-이화도인지-1차보고서-v1.md|
| (10) 기타 |  |
<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | Diffusion Model은 DALL-E 3와 뤼튼과 같은 이미지 생성형 AI에 활용되고 있으며, 최근 주목받고 있는 모델입니다. 이 모델은 고품질의 다양한 이미지를 생성할 수 있다는 장점을 가지며, timestep마다 노이즈를 제거하는 과정을 반복하여 이미지를 생성하는 방식을 채택하고 있습니다. 이러한 샘플링 방식 덕분에 품질 높은 이미지를 다양하게 생성할 수 있지만, 대규모 파라미터로 인한 연산 복잡성, 느린 추론 속도, 높은 메모리 요구량이라는 기술적 한계를 가지고 있습니다. <br> 이 중 저희는 **높은 메모리 요구량**을 본 연구의 문제 정의로 선정하였습니다. Diffusion Model은 이미지 생성 과정에서 각 단계별로 중간 결과를 저장하고 업데이트해야 합니다. 특히, 고해상도 이미지 생성 시 중간 값을 메모리에 유지해야 하므로, 처리해야 할 데이터의 양이 증가하고 메모리 사용량이 급격히 늘어납니다. 이로 인해 GPU 메모리에 대한 의존도가 높아지고, 비용 증가, 메모리 초과 오류와 같은 문제가 빈번히 발생하여 실용성을 저해하고 있습니다. <br> 예를 들어, NeurIPS 2023에 게재된 *Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models* 논문에서도 Diffusion Model의 높은 GPU 메모리 요구량을 주요 문제로 지적한 바 있습니다. <br> 이러한 기술적 배경을 바탕으로, Diffusion Model의 메모리 사용량을 줄이고 효율성을 개선하는 연구는 중요한 주제로 떠오르고 있습니다. |
| (2) 기존 연구와의 비교 | Diffusion 모델에 Quantization을 적용하여 추론 속도를 향상시키는 기존 연구는 다음과 같습니다. 선행 연구 논문은 지도교수님의 추천과 해외 Top-tier 학회 논문을 기준으로 선정되었습니다. <br><br> 1. [Q-Diffusion: Quantizing Diffusion Models (ICCV 2023)](https://arxiv.org/abs/2302.04304) <br> 2. [PTQD: Accurate Post-Training Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2305.10657) <br> 3. [Temporal Dynamic Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2306.02316) <br><br> 위의 세 논문은 모두 재학습이 필요 없는 Post-Training Quantization (PTQ) 방식을 사용하여 Diffusion Model의 다중 timestep 특성에 최적화된 양자화 기법을 제시하고 있습니다. Quantization 과정에서 발생하는 오류 축적 문제는 노이즈 관리 및 분산 조정 등의 방법을 통해 해결하고 있으며, 모델 성능은 FID(Frechet Inception Distance) 점수, 메모리 요구량, 추론 속도 등으로 평가되었습니다. <br> 실험 결과, 양자화를 적용해서 대체로 메모리 요구량은 많이 줄었지만 모델 내 가중치의 상대적 중요성을 고려하지 않고 균일하게 양자화를 적용하여 이미지 생성 품질의 저하의 가능성이 확인되었습니다. <br> 이에 따라, 모델의 메모리 요구량을 효과적으로 줄일 수 있다는 점에서 양자화 기법을 채택하였으나, 동시에 Fisher Information Matrix 기법을 도입하여 layer별로 차등 양자화를 적용함으로써 기존 연구와의 차별성을 두고 이미지 생성 품질 저하를 최소화하고자 하였습니다. |
| (3) 제안 내용 | 본 연구의 목표는 Diffusion Model의 메모리 요구량를 개선하면서도 이미지 품질 저하를 최소화하는 데에 있습니다. 모델의 메모리 요구량을 줄이기 위해 흔히 사용되는 방법 중 하나는 양자화입니다. 그러나 양자화는 필연적으로 정보 손실을 초래하여 이미지 품질 저하를 야기할 수 있습니다. 이를 해결하기 위하여, 본 연구는 모델 전체에 일률적으로 양자화를 적용하는 대신, 이미지 품질에 상대적으로 낮은 기여도를 보이는 부분에는 보다 강하게 양자화를 적용하고, 이미지 품질에 높은 기여도를 보이는 부분에는 양자화 강도를 줄이는 접근법을 제안합니다. 따라서 본 연구는 이러한 차별화된 양자화 적용 방식을 통해 정보 손실을 최소화함으로써 추론 속도의 향상과 동시에 이미지 품질 저하를 최소화할 수 있을 것이라는 가설에 착안하여 연구를 진행하였습니다. <br> 본 연구는 Diffusion Model이 이미지를 생성하는 과정에서 layer별 활성화 정도가 다를 것이라는 가설을 바탕으로 진행되었습니다. 이를 확인하기 위해 Fisher Information Matrix를 활용하여 이미지 생성 과정에서의 layer별 기여도를 분석하였습니다. 레이어별 기여도 분석 결과를 기반으로 가중치의 Fisher 값에 대해 threshold를 설정하였으며, threshold 값보다 작은 Fisher 값을 가지는 가중치의 경우에만 선택적으로 양자화를 적용하는 방식을 도입하였습니다. 이를 통해 메모리 요구량 개선과 이미지 품질 유지 사이의 최적점을 도출하고자 하였습니다. |
| (4) 기대효과 및 의의 | 제안된 방법을 통해 다음과 같은 효과를 기대할 수 있습니다: <br> 1. 메모리 요구량 개선: 이미지 생성 과정에서의 Fisher Information 분석을 통해 기여도가 낮은 가중치에 양자화(값을 더 적은 비트로 표현)를 적용함으로써 전체적인 메모리 사용량을 감소시킬 수 있습니다. <br> 2. 이미지 품질 저하 최소화: 중요한 가중치의 정밀도를 보존함으로써 이미지 품질 저하를 최소화하는 것을 기대할 수 있습니다. |
| (5) 주요 기능 리스트 | DDPM, Weight Magnitude Map, Fisher Information Matrix, Quantization |

<br>
 
# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | **[요구사항1] 메모리 효율성 개선** <br> Diffusion Model에 레이어 적응형 양자화 기법을 도입하여 이미지 생성 과정의 메모리 사용량을 감소시킵니다. <br><br> **[요구사항2] 이미지 품질 보존** <br> 레이어별 기여도 분석을 통해 이미지 생성 과정에서 각 레이어의 중요도를 분석하고, 이를 바탕으로 차등 양자화를 적용하여 이미지 품질 저하를 최소화합니다.|
| (2) 전체 시스템 구성 | ![Pipeline](https://github.com/user-attachments/assets/35301f94-ead7-4ba4-a06b-7bf44d852647) <br> - **[1] Layer-wise Analysis**: Diffusion Model 의 레이어별 Fisher Information 분석 단계 <br> - **[2] Quantization**: 레이어 분석 결과에 따른 차등 양자화 적용 단계 <br><br> 본 연구는 간단한 DDPM 모델을 기반으로 구축된 U-Net을 MNIST 데이터셋에서 1000개의 timestep으로 학습시킨 후, 이를 대상으로 양자화 및 레이어 기여도 분석을 수행합니다. 연구는 크게 두 가지 주요 단계로 이루어집니다. <br><br><br> **[1] Layer-wise Analysis** <br><br> <img src="https://github.com/user-attachments/assets/eff9f21a-b80d-47e6-9df2-991ebd1ae817" alt="Eq1" style="width:200px; height:auto;"> &nbsp;&nbsp;(1) &nbsp;&nbsp;&nbsp;&nbsp; <img src="https://github.com/user-attachments/assets/a00e62e0-5b47-444d-a220-449e0347324c" alt="Eq2" style="width:200px; height:auto;"> &nbsp;&nbsp; (2) <br> Fisher Information은 특정 모델 가중치가 출력에 미치는 영향을 정량적으로 평가하는 척도로, 가중치의 중요도를 객관적으로 측정할 수 있습니다. Fisher 값이 높을수록 해당 가중치가 모델의 전반적인 성능에 더욱 중요한 기여를 한다는 것을 의미합니다. 본 연구에서는 먼저 손실 계산 단계에서 모델 출력과 목표값(ground truth) 간의 차이를 계산한 후, 이를 가중치에 대해 미분하여 Fisher 값을 산출하고(1), 이를 각 타임스텝과 레이어별로 저장하였습니다. 또한, 최대값을 기준으로 Fisher 값을 정규화함으로써 각 레이어와 타임스텝의 상대적 중요도를 용이하게 비교할 수 있게 하였습니다(2). <br><br> **[2] Quantization** <br> Fisher 값에 대한 분석 결과를 바탕으로 양자화 실험을 세 가지 주요 접근법으로 나누어 수행하였습니다. 모든 실험에서 FP32 자료형을 FP16으로 변환하는 양자화 방식으로 일관되게 적용하였으며, 성능 평가는 Fréchet Inception Distance(FID)와 모델 메모리 크기를 주요 지표로 활용하였습니다. FID 는 실제 이미지 5,000개와 샘플링 이미지 5,000개를 기반으로 계산되며, 낮은 값일수록 생성 이미지의품질이 우수함을 의미합니다. |
| (3) 주요엔진 및 기능 설계 | 해당 연구는 Diffusion 모델 기반 U-Net을 사용하여 MNIST 데이터에서 이미지를 생성하는 과정으로, Fisher Information을 통해 레이어와 가중치의 중요도를 분석하고, 이를 바탕으로 모델의 양자화와 성능 최적화를 수행합니다. 모델은 timestep마다 노이즈를 점진적으로 제거하여 이미지를 생성하며, 메모리 사용량을 줄이고 연산 효율을 높이기 위해 mixed precision(양자화)를 적용합니다. <br><br> **1) 사용된 주요 라이브러리** <br> - **PyTorch**: 모델 생성, 학습, 최적화, 텐서 연산 등 전체적인 딥러닝 파이프라인 구현합니다. <br> - **torchvision**: MNIST 데이터셋 다운로드 및 전처리에 사용합니다. <br> - **einops**: 텐서 형태 변환을 위해 사용하여 모델의 어텐션 및 U-Net 레이어의 텐서 조작을 간편하는 기능을 합니다. <br> - **tqdm**: 학습 및 이미지 생성 과정에서 진행 상황을 시각적으로 표시합니다. <br>  - **matplotlib**: 모델 학습 결과, FID 점수, Fisher Information 분석을 시각화 합니다. <br><br> **2) 주요 모듈 설명 및 역할**<br> ***a) 데이터 준비 및 전처리 모듈*** <br> - **기능**: MNIST 데이터를 로드하고 모델에 입력 가능한 텐서 형태로 변환합니다. <br> - **구현 내용**: `datasets.MNIST`와 `DataLoader`를 사용해 데이터를 배치 단위로 로드하고, `transforms.ToTensor()`로 텐서 변환합니다. 데이터를 효과적으로 모델에 전달하여 학습과 생성에 활용합니다. <br><br> ***b) 모델 구성 모듈 (U-Net 및 레이어 구성)*** <br> - **임베딩 모듈** (`SinusoidalEmbeddings`): 각 timestep에 해당하는 임베딩 벡터를 생성해, Diffusion 모델이 시간 정보를 학습하게 합니다. <br> - **Residual 블록** (`ResBlock`): 잔차 연결을 통해 학습 안정성을 높이고 정보 손실을 방지합니다. <br> - **어텐션 모듈** (`Attention`): 특정 레이어에 다중 헤드 어텐션을 추가해 중요도에 따라 가중치를 조절합니다. <br> - **U-Net 레이어** (`UnetLayer`): 업샘플링과 다운샘플링 수행, 필요 시 어텐션 적용합니다. <br> - **전체 U-Net 모델** (`UNET`): 모든 레이어를 연결하여 인코더-디코더 구조를 통해 노이즈 제거 및 이미지 생성합니다. <br><br> ***c) Diffusion 과정 및 스케줄러*** <br> - **스케줄러** (`DDPM_Scheduler`): timestep마다 노이즈를 추가/제거하기 위한 파라미터 α와 β 값을 설정합니다. <br> - **훈련 함수** (`train`): 각 epoch마다 손실을 계산하고, **EMA(Exponential Moving Average)**로 모델의 학습을 안정화하며 점진적으로 최적화합니다. <br><br> ***d) Fisher Information 계산 및 양자화 모듈*** <br> - **Fisher Information 계산**: 각 timestep에서 각 레이어의 가중치 중요도를 평가하여, 양자화 대상과 비대상을 결정합니다. <br> - **가중치 크기 분석**: 각 레이어의 가중치 크기를 분석하여 모델의 기여도를 시각화합니다. <br>  - **양자화 적용 및 혼합 정밀도 모델**: `apply_mixed_precision`: threshold 를 기준으로 특정 레이어의 weight는 `float32`로 유지하고, 나머지 weight 를 `float16`으로 변환해 메모리 사용량 절감 및 연산 최적화합니다. `inference_all_half_quant`: 양자화된 모델로 이미지를 생성하고, α와 β 값도 `float16`으로 변환하여 효율성을 높임니다. <br><br>  ***e) 이미지 생성 및 평가 모듈*** <br> - **Inference 및 이미지 생성** (`inference`, `inference_all_half_quant`): 노이즈 텐서에서 점진적으로 노이즈를 제거하여 최종 이미지를 생성합니다. <br>  - **FID 점수 계산** (`compute_fid_score`): 실제 이미지와 생성된 이미지 간의 차이를 측정해 모델 성능 평가합니다. FID 계산을 위하여 timm 라이브러리의 ModelEmaV3 를 사용합니다. <br> - **Fisher Information 시각화**: Fisher Information Value를 timestep별로 시각화하여, 각 레이어와 가중치의 중요도를 확인합니다. <br><br><br> **3. 주요 기능 및 데이터 흐름** <br> **a) 훈련 단계**: 데이터 준비 → 모델 학습(`train`) → 노이즈 스케줄러를 통한 점진적 학습 → Fisher Information 계산합니다. <br> **b) Fisher Information 분석 및 양자화**: 각 timestep의 Fisher Information을 계산하여 특정 Threshold 이하의 가중치만 양자화하여 효율성을 향상시킵니다. <br> **c) Inference 및 시각화**: 양자화된 모델을 사용해 이미지를 생성하고 FID Score로 성능 평가합니다. <br> |
| (4) 주요 기능의 구현 | 본 연구에서 사용된 Diffusion Model은 [다음의 글](https://towardsdatascience.com/diffusion-model-from-scratch-in-pytorch-ddpm-9d9760528946)을 참고하여 구현하였습니다. 해당 Simple Diffusion Model은 MNIST 데이터셋에서 수행되었으며, 6개 레이어의 U-Net 아키텍처로 구현되었습니다. 모델은 1,000 타임스텝을 기준으로 학습되었습니다. <br><br> **[1] Layer-wise 실험 결과** <br> <img width="300" alt="Fisher Information Map per Layers (w:o log scale)" src="https://github.com/user-attachments/assets/de16eda0-e1fc-40d2-896f-6d0925f718ca"> &nbsp; <img width="300" alt="Fisher Information Map per Layers (w: log scale)" src="https://github.com/user-attachments/assets/e05c5093-bbc8-47f5-adcc-22a3898cec2a"><br>*(좌) 타임스텝에 따른 레이어별 Fisher 값 (Log scale 미적용) / (우) 타임스텝에 따른 레이어별 Fisher 값 (Log scale 적용)*<br><br>레이어별 Fisher Information 값을 분석한 결과, 레이어1과 2는 현저히 높은 기여도를 나타낸 반면, 레이어 3, 4, 5, 6은 상대적으로 낮은 기여도를 보였습니다. 또한, 타임스텝이 진행되어 최종 이미지에 근접할수록 Fisher 값이 증가하는 경향을 관찰할 수 있었습니다. 이를 바탕으로 본 연구는 마지막 타임스텝의 Fisher 값을 기준으로 차등 양자화 전략을 설계하였습니다. <br><br> **[2] Quantization 실험 결과** <br> **1. 단일 임곗값 설정 **<br> Fisher 값 분석 결과를 바탕으로, 모델 전체 가중치에 적용될 단일 임계값을 설정하고, 이 임계값 미만의 Fisher 값을 갖는 가중치에 대하여 양자화를 적용하였습니다. <br><br> **2.레이어 그룹별 임곗값 설정** <br> Fisher Information 분석 결과에 따르면, 레이어 1 과 2 는 최대값 1e5 수준의 매우 높은 기여도를 보였으며, 레이어 3, 4, 5 는 1e-1, 레이어 6 은 1e 수준으로 상대적으 로 낮은 기여도를 나타냈습니다. 이러한 분석을 바탕으로 레이어 1 과 2 를 단일 그룹으로 묶고, 나머지 레이어를 하나의 그룹으로 처리한 설정(레이어 12 / 3456)과 레이어 1과 2를 하나의 그룹으로 유지하면서 나머지 레이어를 더욱 세분화한 설정(레이어 12 / 345 / 6)으로 나누어 실험을 진행하였습니다. <br><br> **3.레이어별 임곗값 설정** <br> 레이어별 임곗값 설정을 위해 임곗값 비율을 도입하였습니다. 임곗값 비율 p 가 주어졌을 때, 해당 레이어의 피셔 값 분포에서 (1-p)×100 백분위수에 해당하는 값을 임곗값으로 선택합니다. 예를 들어, 임곗값 비율이 0.3 인 경우, 피셔 값 분포의 상위 30%에 해당하는 값이 해당 레이어의 임곗값으로 채택됩니다. 임계값 비율을 0.1부터 0.5까지 0.05씩 증가시키면서 실험한 결과는 다음과 같습니다. <br> <img src="https://github.com/user-attachments/assets/9558b7d0-a09e-47c7-80c2-50170f2802bd" alt="Eq2" style="width:400px; height:auto;">|
| (5) 기타 | 11월 내에 진행되는 학회 및 공모전을 탐색 중에 있으며, 만약 있다면 참가할 예정입니다. |

<br>

# Evaluation
| 항목 | 내용 |
|:---  |---  |
|(1) 평가 항목 |  |
|(2) 평가 기준 |  |
|(3) 평가 방식 |  |
|(4) 평가 내용/결과 |  |

<br>

# Conclusion
| 항목 | 내용 |
|:---  |---  |
|(1) 결론(Conclusion)| |
