# Team-Info
| (1) 과제명 | Layer-Adaptive Quantization on Diffusion Model using Fisher Information <br> 피셔 정보를 활용한 확산 모델에의 레이어 적응형 양자화
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 23-이화도인지 |
| (3) 팀 구성원 | 김도은 (2076035): 리더, *연구 및 논문 작성* <br> 박인애 (2171088): 팀원, *연구 및 논문 작성* <br> 변지은 (2076193) : 팀원, *연구 및 논문 작성*			 |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 팀 멘토 | 박준석 멘토님 / 삼성전자 / 수석 연구원 |
| (6) 과제 분류 | 연구 과제 |
| (6) 과제 키워드 | Diffusion Model, Fisher Information Matrix, Quantization |
| (7) 과제 내용 요약 | Diffusion Model에 대해 레이어 적응형 양자화 기법이 제안되었으며, U-Net 구조에서 개별 레이어의 중요도를 평가하기 위해 Fisher 정보가 활용되었습니다. 레이어의 중요도에 따라 차등적인 양자화 임계값을 적용함으로써 메모리 효율성을 최적화하면서도 이미지 품질을 유지할 수 있었습니다. MNIST 데이터셋에서의 실험 결과, 모델 크기가 49.4% 감소하였고, 균일 양자화와 비교했을 때 FID가 최대 7% 개선되었습니다. 본 연구는 Fisher 정보를 기반으로 한 양자화가 경량화되고 효율적인 Diffusion Model 개발에 효과적임을 입증하였습니다. <br><br> A layer-adaptive quantization method for Diffusion Models is proposed, utilizing Fisher Information to evaluate the importance of individual layers in the U-Net architecture. By applying differential quantization thresholds based on layer significance, the approach optimizes memory efficiency while preserving image quality. Experiments on the MNIST dataset show a 49.4% reduction in model size and up to a 7% improvement in FID compared to uniform quantization. The findings demonstrate the effectiveness of Fisher Information- guided quantization for developing lightweight and efficient Diffusion Models.|
| (8) 주요 Link | 과제 GIT Address: https://github.com/Ewha-DoInJi/growth-research <br> 1차 보고서: https://github.com/Ewha-DoInJi/growth-research/blob/main/reports/23-이화도인지-1차보고서-v1.md <br> 2차 보고서: https://github.com/Ewha-DoInJi/growth-research/blob/main/reports/23-이화도인지-2차보고서-v2.md|
| (10) 기타 | 2024 대한전자공학회 학술심포지움 논문 투고 완료 (심사 중, 12월 18일 결과 발표 예정)  |
<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | Diffusion Model은 DALL-E 3와 뤼튼과 같은 이미지 생성형 AI에 활용되고 있으며, 최근 주목받고 있는 모델입니다. 이 모델은 고품질의 다양한 이미지를 생성할 수 있다는 장점을 가지며, timestep마다 노이즈를 제거하는 과정을 반복하여 이미지를 생성하는 방식을 채택하고 있습니다. 이러한 샘플링 방식 덕분에 품질 높은 이미지를 다양하게 생성할 수 있지만, 대규모 파라미터로 인한 연산 복잡성, 느린 추론 속도, 높은 메모리 요구량이라는 기술적 한계를 가지고 있습니다. <br> 이 중 저희는 **높은 메모리 요구량**을 본 연구의 문제 정의로 선정하였습니다. Diffusion Model은 이미지 생성 과정에서 각 단계별로 중간 결과를 저장하고 업데이트해야 합니다. 특히, 고해상도 이미지 생성 시 중간 값을 메모리에 유지해야 하므로, 처리해야 할 데이터의 양이 증가하고 메모리 사용량이 급격히 늘어납니다. 이로 인해 GPU 메모리에 대한 의존도가 높아지고, 비용 증가, 메모리 초과 오류와 같은 문제가 빈번히 발생하여 실용성을 저해하고 있습니다. <br> 예를 들어, NeurIPS 2023에 게재된 *Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models* 논문에서도 Diffusion Model의 높은 GPU 메모리 요구량을 주요 문제로 지적한 바 있습니다. <br> 이러한 기술적 배경을 바탕으로, Diffusion Model의 메모리 사용량을 줄이고 효율성을 개선하는 연구는 중요한 주제로 떠오르고 있습니다. |
| (2) 기존 연구와의 비교 | Diffusion 모델에 Quantization을 적용하여 추론 속도를 향상시키는 기존 연구는 다음과 같습니다. 선행 연구 논문은 지도교수님의 추천과 해외 Top-tier 학회 논문을 기준으로 선정되었습니다. <br><br> 1. [Q-Diffusion: Quantizing Diffusion Models (ICCV 2023)](https://arxiv.org/abs/2302.04304) <br> 2. [PTQD: Accurate Post-Training Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2305.10657) <br> 3. [Temporal Dynamic Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2306.02316) <br><br> 위의 세 논문은 모두 재학습이 필요 없는 Post-Training Quantization (PTQ) 방식을 사용하여 Diffusion Model의 다중 timestep 특성에 최적화된 양자화 기법을 제시하고 있습니다. Quantization 과정에서 발생하는 오류 축적 문제는 노이즈 관리 및 분산 조정 등의 방법을 통해 해결하고 있으며, 모델 성능은 FID(Frechet Inception Distance) 점수, 메모리 요구량, 추론 속도 등으로 평가되었습니다. <br> 실험 결과, 양자화를 적용해서 대체로 메모리 요구량은 많이 줄었지만 모델 내 가중치의 상대적 중요성을 고려하지 않고 균일하게 양자화를 적용하여 이미지 생성 품질의 저하의 가능성이 확인되었습니다. <br> 이에 따라, 모델의 메모리 요구량을 효과적으로 줄일 수 있다는 점에서 양자화 기법을 채택하였으나, 동시에 Fisher Information Matrix 기법을 도입하여 layer별로 차등 양자화를 적용함으로써 기존 연구와의 차별성을 두고 이미지 생성 품질 저하를 최소화하고자 하였습니다. |
| (3) 제안 내용 | 본 연구의 목표는 Diffusion Model의 메모리 요구량를 개선하면서도 이미지 품질 저하를 최소화하는 데에 있습니다. 모델의 메모리 요구량을 줄이기 위해 흔히 사용되는 방법 중 하나는 양자화입니다. 그러나 양자화는 필연적으로 정보 손실을 초래하여 이미지 품질 저하를 야기할 수 있습니다. 이를 해결하기 위하여, 본 연구는 모델 전체에 일률적으로 양자화를 적용하는 대신, 이미지 품질에 상대적으로 낮은 기여도를 보이는 부분에는 보다 강하게 양자화를 적용하고, 이미지 품질에 높은 기여도를 보이는 부분에는 양자화 강도를 줄이는 접근법을 제안합니다. 따라서 본 연구는 이러한 차별화된 양자화 적용 방식을 통해 정보 손실을 최소화함으로써 추론 속도의 향상과 동시에 이미지 품질 저하를 최소화할 수 있을 것이라는 가설에 착안하여 연구를 진행하였습니다. <br> 본 연구는 Diffusion Model이 이미지를 생성하는 과정에서 layer별 활성화 정도가 다를 것이라는 가설을 바탕으로 진행되었습니다. 이를 확인하기 위해 Fisher Information Matrix를 활용하여 이미지 생성 과정에서의 layer별 기여도를 분석하였습니다. 레이어별 기여도 분석 결과를 기반으로 가중치의 Fisher 값에 대해 threshold를 설정하였으며, threshold 값보다 작은 Fisher 값을 가지는 가중치의 경우에만 선택적으로 양자화를 적용하는 방식을 도입하였습니다. 이를 통해 메모리 요구량 개선과 이미지 품질 유지 사이의 최적점을 도출하고자 하였습니다. |
| (4) 기대효과 및 의의 | 제안된 방법을 통해 다음과 같은 효과를 기대할 수 있습니다: <br> 1. 메모리 요구량 개선: 이미지 생성 과정에서의 Fisher Information 분석을 통해 기여도가 낮은 가중치에 양자화(값을 더 적은 비트로 표현)를 적용함으로써 전체적인 메모리 사용량을 감소시킬 수 있습니다. <br> 2. 이미지 품질 저하 최소화: 중요한 가중치의 정밀도를 보존함으로써 이미지 품질 저하를 최소화하는 것을 기대할 수 있습니다. |
| (5) 주요 기능 리스트 | DDPM, Weight Magnitude Map, Fisher Information Matrix, Quantization |

<br>
 
# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | **[요구사항1] 메모리 효율성 개선** <br> Diffusion Model에 레이어 적응형 양자화 기법을 도입하여 이미지 생성 과정의 메모리 사용량을 감소시킵니다. <br><br> **[요구사항2] 이미지 품질 보존** <br> 레이어별 기여도 분석을 통해 이미지 생성 과정에서 각 레이어의 중요도를 분석하고, 이를 바탕으로 차등 양자화를 적용하여 이미지 품질 저하를 최소화합니다.|
| (2) 전체 시스템 구성 | ![Pipeline](https://github.com/user-attachments/assets/35301f94-ead7-4ba4-a06b-7bf44d852647) <br> - **[1] Layer-wise Analysis**: Diffusion Model 의 레이어별 Fisher Information 분석 단계 <br> - **[2] Quantization**: 레이어 분석 결과에 따른 차등 양자화 적용 단계 <br><br> 본 연구는 간단한 DDPM 모델을 기반으로 구축된 U-Net을 MNIST 데이터셋에서 1000개의 timestep으로 학습시킨 후, 이를 대상으로 양자화 및 레이어 기여도 분석을 수행합니다. 연구는 크게 두 가지 주요 단계로 이루어집니다. <br><br><br> **[1] Layer-wise Analysis** <br><br> <img src="https://github.com/user-attachments/assets/eff9f21a-b80d-47e6-9df2-991ebd1ae817" alt="Eq1" style="width:200px; height:auto;"> &nbsp;&nbsp;(1) &nbsp;&nbsp;&nbsp;&nbsp; <img src="https://github.com/user-attachments/assets/a00e62e0-5b47-444d-a220-449e0347324c" alt="Eq2" style="width:200px; height:auto;"> &nbsp;&nbsp; (2) <br> Fisher Information은 특정 모델 가중치가 출력에 미치는 영향을 정량적으로 평가하는 척도로, 가중치의 중요도를 객관적으로 측정할 수 있습니다. Fisher 값이 높을수록 해당 가중치가 모델의 전반적인 성능에 더욱 중요한 기여를 한다는 것을 의미합니다. 본 연구에서는 먼저 손실 계산 단계에서 모델 출력과 목표값(ground truth) 간의 차이를 계산한 후, 이를 가중치에 대해 미분하여 Fisher 값을 산출하고(1), 이를 각 타임스텝과 레이어별로 저장하였습니다. 또한, 최대값을 기준으로 Fisher 값을 정규화함으로써 각 레이어와 타임스텝의 상대적 중요도를 용이하게 비교할 수 있게 하였습니다(2). <br><br> **[2] Quantization** <br> Fisher 값에 대한 분석 결과를 바탕으로 양자화 실험을 세 가지 주요 접근법으로 나누어 수행하였습니다. 모든 실험에서 FP32 자료형을 FP16으로 변환하는 양자화 방식으로 일관되게 적용하였으며, 성능 평가는 Fréchet Inception Distance(FID)와 모델 메모리 크기를 주요 지표로 활용하였습니다. FID 는 실제 이미지 5,000개와 샘플링 이미지 5,000개를 기반으로 계산되며, 낮은 값일수록 생성 이미지의품질이 우수함을 의미합니다. |
| (3) 주요엔진 및 기능 설계 | MNIST 데이터셋으로 훈련된 Diffusion Model이 이미지를 생성하는 과정에서, Fisher Information을 통해 레이어와 가중치의 중요도를 분석하고, 분석한 결과를 바탕으로 양자화를 적용하여 모델의 메모리 사용량을 절감하면서도 성능 저하를 최소화하는 것을 목표로 합니다. <br><br> **1. 사용된 주요 라이브러리** <br><br> - **PyTorch**: 모델 생성, 학습, 최적화, 텐서 연산 등 전체적인 딥러닝 파이프라인 구현합니다. <br> - **PyTorch**: 모델 생성, 학습, 최적화 및 텐서 연산 수행. <br> - **torchvision**: MNIST 데이터셋 다운로드 및 전처리. <br> - **einops**: 텐서 변환으로 모델 어텐션 및 U-Net 레이어의 효율적인 데이터 조작 지원. <br> - **tqdm**: 학습 및 이미지 생성 과정에서 진행 상황 시각화. <br> - **matplotlib**: Fisher Information 분석 및 모델 결과 시각화. <br><br>  **2. 주요 모듈 설명 및 역할**<br><br> ***a) 데이터 준비 및 전처리*** <br> - **역할**: MNIST 데이터셋 로드 및 텐서로 변환하여 모델 학습 및 평가에 적합하게 처리. <br> - **구현**: `datasets.MNIST`와 `DataLoader`를 사용하여 배치 단위로 데이터를 로드하며, `transforms.ToTensor()`로 정규화된 텐서를 생성. <br><br> ***b) 모델 구성 모듈 (U-Net)*** <br> **i) 임베딩 모듈** <br> - **역할**: 각 timestep에 해당하는 시간 정보를 벡터로 변환하여 모델에 제공. <br> - **특징**: Sinusoidal 함수를 사용하여 시간 정보를 임베딩. <br> **ii) Residual 모듈** <br> - **역할**: 잔차 연결로 정보 손실 방지 및 학습 안정화. <br> - **구성 요소**: GroupNorm, Conv2D, Dropout. <br> **iii) 어탠션 모듈(Attention)** <br> - **역할**: 특정 레이어에 어텐션 메커니즘을 적용하여 중요도를 조정. <br> - **특징**: 다중 헤드 어텐션 사용. <br> **iv). U-Net 레이어(U-Net Layer)** <br> - **역할**: 업샘플링, 다운샘플링 및 어텐션 적용. <br> - **특징**: Residual 블록과 업/다운샘플링 Conv 레이어로 구성. <br> **v) 전체 U-Net 모델(U-Net)** <br> - **역할**: 인코더-디코더 구조로 노이즈를 제거하고 이미지를 생성. <br> - **특징**: 6개의 레이어로 구성된 멀티스케일 구조. <br><br> ***c) Diffusion 과정 및 스케줄러*** <br> - **DDPM_Scheduler**: timestep마다 노이즈를 추가/제거하기 위한 α, β 파라미터를 설정. <br> - **훈련 함수 (train)**: 각 epoch 동안 손실 계산 및 EMA(Exponential Moving Average)를 사용해 학습 안정성을 유지. <br><br> ***d) Fisher Information 계산 및 양자화*** <br> i) **Fisher Information 계산**: 각 timestep에서 각 레이어의 가중치 중요도를 평가. <br> ii) **가중치 크기 분석**: 각 레이어의 Fisher Information을 분석하여 모델의 기여도를 시각화. <br> iii) **양자화 적용**: 특정 Threshold를 기준으로 중요도가 낮은 가중치를 파이토치의 half 함수로 양자화(FP16)하여 메모리 사용량 감소 및 효율성 향상. <br><br> ***e) 이미지 생성 및 평가*** <br> - **Inference**: 노이즈 텐서에서 점진적으로 노이즈를 제거하여 최종 이미지 생성. <br> - **FID 점수 계산**: 실제 이미지와 생성된 이미지 간의 차이를 측정하여 성능 평가. <br> - **시각화**: Fisher Information 및 생성된 이미지를 시각화하여 분석 결과를 정리. <br><br>  **3. 주요 기능 및 데이터 흐름**<br><br> ***a) 훈련 단계*** <br> - 데이터 준비 → 모델 학습(train) → 노이즈 스케줄러를 통한 점진적 학습 → Fisher Information 계산. <br><br> ***b) Fisher Information 분석 및 양자화*** <br> - timestep별 개별 레이어의 Fisher Information을 계산하고, 중요도가 낮은 가중치를 파이토치 라이브러리의 half 함수로 FP32→FP16 으로 양자화하여 모델 효율성 향상. <br><br> ***c) Inference 및 성능 평가*** <br> - 양자화된 모델을 사용해 이미지를 생성하고, FID score 및 모델의 크기로 성능을 평가. <br> - 생성된 이미지와 분석 결과를 시각화. |
| (4) 주요 기능의 구현 |본 연구에서는 간단한 DDPM(Denoising Diffusion Probabilistic Model)을 기반으로 한 Diffusion Model을 구현하였으며, 6개의 Layer로 구성된 U-Net을 사용하여 MNIST 데이터셋에서 1,000개의 timestep으로 학습을 진행하였습니다. 또한, U-Net 구조를 기반으로 각 Layer의 Fisher Information 값을 산출하여 Layer별 중요도를 분석하였습니다. Fisher Information 값은 모델 출력에 특정 가중치가 미치는 영향을 정량적으로 평가하는 척도로, 값이 클수록 해당 가중치의 기여도가 더 크다는 것을 의미합니다. 이 값을 각 timestep 및 Layer별로 저장한 뒤, 정규화를 통해 상대적 중요도를 비교하였습니다. <br><br> **Fisher inforamtion value 분석 결과** <br> <br>**1) Layer별 timestep에 따른 weight값 결과** <br>다음 이미지는 timestep별 Layer의 weight 값을 보여줍니다. <br><img src="https://github.com/user-attachments/assets/b4db0cf1-92c1-46a3-9505-96d943577661" alt="fisher_information_map_All_layers" width="500" /><br><br><br>분석 결과, Layer 1과 Layer 2는 유의미한 weight 변화를 보였으며, 상대적으로 큰 weight 값을 가졌습니다. 하지만 Layer 3, 4, 5, 6은 작은 값을 가지며 0에 수렴하는 경향을 보였습니다. 이를 보완하기 위해 log scale 정규화를 적용하여 값을 시각화하였습니다. <br> <br><img src="https://github.com/user-attachments/assets/b2090dba-a65a-47e9-a2e7-5ab36c31ae3b" alt="fisher_information_map_All_layers" width="500"><br> <br> log scale 정규화를 적용한 결과에서도 Layer 1, 2, 6이 비교적 높은 기여도를 나타냈습니다. 전반적으로 weight 값의 변화 양상은 모든 Layer에서 유사한 패턴을 보였으나, 특정 Layer가 생성 과정에서 더 중요한 역할을 하는 것을 확인할 수 있었습니다. <br><br> **2) Layer별 weight의 Fisher 값 분석** <br>다음 이미지는 각 Layer에 속한 weight 종류별 Fisher 값을 시각화한 것입니다.<br>(x축: 특정 Layer에 속한 weight 종류 / y축: Fisher 값) <br><img src="https://github.com/user-attachments/assets/3837dfb5-5e4d-479b-87f4-f03e8c6c4286" alt="fisher_information_value_final_gradation (4)" width="500"><br> <br> Layer 1, 2, 6은 상대적으로 높은 Fisher 값을 보였으며, 특히 Layer 1과 Layer 2는 가장 큰 Fisher 값에 도달하였습니다. 반면, Layer 3, 4, 5는 상대적으로 낮은 Fisher 값을 나타냈습니다.<br>또한, timestep이 진행됨에 따라(노이즈 상태에서 완성된 이미지 상태로 이동) 최종 이미지에 가까워질수록 Fisher 값이 증가하는 경향이 관찰되었습니다. 모든 weight에서 Fisher 값이 증가하는 동일한 경향성을 실험적으로 검증하였으며, 이를 바탕으로 본 연구는 Fisher 값이 가장 높은 최종 timestep(완성 이미지 상태)을 기준으로 양자화 실험을 진행하였습니다. <br> <br>**양자화 실험**<br> <br>본 연구에서는 Fisher Information 기반 분석 결과를 바탕으로 세 가지 양자화 접근법을 설계하여 실험을 진행하였습니다. 모든 실험은 FP32 자료형을 FP16으로 변환하는 양자화 방식을 적용하였으며, 성능은 Fréchet Inception Distance(FID)와 모델 크기를 기준으로 평가하였습니다.<br><br> **1) 단일 임곗값 설정** <br><br>모델 전체 가중치에 단일 임곗값을 적용하고, 이 값보다 작은 Fisher 값을 가진 가중치에만 양자화를 적용하였습니다. 단일 임곗값 방식은 단순하지만, 레이어별 Fisher 값의 차이를 반영하지 못하여 상대적으로 제한적인 성능 향상을 보였습니다.<br><br> **2) 레이어 그룹별 임곗값 설정**<br> <br>Fisher 값 분석 결과를 기반으로 레이어를 두 그룹으로 나누어 각각 다른 임곗값을 설정하였습니다.- Layer 1과 2는 높은 Fisher 값을 가지는 그룹으로 설정하고, 나머지 Layer 3, 4, 5, 6은 상대적으로 낮은 Fisher 값을 가지는 그룹으로 분류하였습니다. - 또한, Layer 3, 4, 5와 Layer 6을 추가적으로 세분화하여 더 정밀한 그룹화 실험을 진행하였습니다. 레이어 그룹별 접근법은 메모리 절감 효과를 극대화하면서도 전체적인 성능 저하를 최소화하는 결과를 보였습니다. <br><br> **3) 레이어별 임곗값 설정** <br><br> **3-1)임곗값 비율 방식** <br><br> 레이어별 Fisher 값 분포를 기반으로 특정 비율(p)을 적용하여 상위 100×(1−p)%에 해당하는 값을 임곗값으로 설정하였습니다. 예를 들어, p=0.25일 경우, Fisher 값 분포의 상위 25% 값을 임곗값으로 사용하였습니다. 이 방식은 FID 성능에서 가장 우수한 결과를 보여주었습니다.<br><br> **3-2)평균 및 분산 기반 방식**<br> <br> 각 레이어의 Fisher 값에 대한 평균과 분산을 활용하여 상한 및 하한 임곗값을 설정한 뒤, 이를 기준으로 가중치를 양자화하였습니다. 이 방식은 비교적 간단한 구현으로도 안정적인 성능을 보였습니다.<br><br> **추가 결과 분석**<br> <br> - 레이어별 임곗값 비율 방식(p=0.25)을 사용했을 때, FID 점수는 전체 양자화 방식 대비 약 7% 개선되었으며, 모델 크기는 양자화 이전보다 약 23.8% 감소하는 성과를 보였습니다. - 레이어 그룹별 임곗값 설정은 FID를 5% 개선시키는 동시에 모델 크기를 49.4% 감소시켜 메모리 효율성에서 가장 두드러진 결과를 보였습니다. - 단일 임곗값 방식은 간단한 접근법임에도 불구하고, FID와 메모리 감소에서 적절한 균형을 이루는 결과를 보였으나, 다른 레이어 접근 방식에 비하여 아쉬운 결과를 보였습니다.|
| (5) 기타 | 2024 대한전자공학회 학술심포지움 논문 투고 완료 (심사 중, 12월 18일 결과 발표 예정) |

<br>

# Evaluation
| 항목 | 내용 |
|:---  |---  |
|(1) 평가 항목 선정 | 본 연구의 목표는 Diffusion Model이 이미지 생성 시의 메모리 사용량을 개선하면서도 이미지 품질 저하를 최소화하는 것입니다. <br> 우선 메모리 사용량 개선 여부를 평가하기 위해서는 모델의 weight 파라미터가 차지하는 전체 메모리 크기(bytes)를 통해 비교하였습니다. Diffusion Model과 같은 딥러닝 모델에서 weight 파라미터는 학습 및 추론 과정에서 메모리 사용량의 대부분을 차지하는 주요 구성 요소이며, 특히 Diffusion Model과 같은 대규모 생성 모델에서는 그 중요성이 더욱 두드러집니다. Weight 파라미터의 크기는 모델 로드 시 GPU 메모리 사용량에 직접적으로 영향을 미치며, 이를 줄이는 것은 GPU 메모리의 효율적 활용을 가능하게 하고 저장 용량 및 데이터 전송 비용을 절감하는 데 기여합니다. <br> 다음으로 이미지 품질 저하 여부를 평가하기 위해서는 FID(Frechet Inception Distance) 지표를 사용해야 합니다. 이미지 품질 저하 여부를 평가하기 위해 FID 지표를 사용하는 것은 Diffusion Model의 생성 성능을 객관적이고 정량적으로 측정할 수 있기 때문입니다. FID는 생성된 이미지와 실제 이미지 간의 통계적 분포 차이를 계산하여 이미지의 품질과 다양성을 평가하는 데 널리 사용되는 표준 지표로, 특히 고품질 이미지 생성 모델의 성능 비교에서 그 유효성이 입증되어 왔습니다. 이는 단순히 픽셀 단위의 차이를 측정하는 것이 아니라, 이미지의 고차원 특성을 반영하여 사람의 인지적 관점과 유사한 방식으로 품질을 평가할 수 있도록 설계되었습니다. |
|(2) 평가 항목 A - 메모리 사용량(모델 크기) | **1. 평가 항목 설명** <br><br> ***a)메모리 사용량*** <br> 메모리 사용량은 딥러닝 모델이 실행되거나 학습 및 추론을 수행할 때, GPU나 CPU 메모리에서 소비되는 총 용량을 의미합니다. 이는 주로 모델의 weight 파라미터, 중간 계산 결과(activations), 옵티마이저 상태, 입력 데이터 등이 차지하는 메모리 공간으로 구성됩니다. 메모리 사용량은 모델의 크기와 데이터 처리 과정에 따라 결정되며, 메모리 요구량이 높을 경우 하드웨어 비용 증가와 메모리 초과 오류 등의 문제가 발생할 수 있습니다. 따라서 메모리 사용량을 최적화하는 것은 모델의 효율성과 활용성을 높이는 데 중요한 요소로 작용합니다. <br><br> ***b)모델 크기(평가 지표)*** <br> 메모리 사용량 평가 시 사용되는 평가 지표인 모델의 weight 파라미터가 차지하는 전체 메모리 크기(bytes), 즉 “모델 크기” 는딥러닝 모델의 weight 파라미터가 메모리 상에서 차지하는 총 용량을 의미하며, 이는 곧 weight 텐서 각각의 메모리 사용량을 합산한 값을 뜻합니다. 모델 크기는 (1)각 weight의 자료형 크기와 (2)해당 weight를 구성하는 요소의 개수를 기반으로 측정합니다. <br><br> (1) 먼저 weight의 자료형 크기는 weight 텐서의 자료형(`dtype`)에 따라 각 요소가 메모리에서 차지하는 바이트 크기입니다. 일반적으로 사용되는 자료형과 요소당 크기는 다음과 같습니다.: FP32 = 4bytes, FP16 = 2 bytes, INT8 = 1 byte. <br> (2) 해당 weight를 구성하는 요소의 개수, 즉, 파라미터 개수(Parameter Count)는 각 weight 텐서가 담고 있는 요소(숫자)의 총 개수, 즉 텐서의 크기(dimensions)와 같습니다. 예를 들어, 텐서가 `shape=(256, 256)`이라면, 파라미터 개수는 256×256=65,536 입니다. <br> 모델 크기는 각 텐서의 크기를 모두 합산하여 구하며, 이를 수식으로 정리하면 다음과 같습니다. <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/c9c6a606-0d62-46f1-bd26-360edb957a99" /> <br><br>  **2. 평가 기준** <br><br> - **(10% ~ 20%) 감소: 약간 감소** <br> 모델 크기가 줄었지만, 메모리 효율성 개선의 체감 효과는 크지 않을 가능성이 높습니다. 실질적인 메모리 초과 문제를 해결하기에는 부족할 수 있으나, 경량화 기술의 초기 효과를 확인할 수 있는 단계입니다.<br> - **(20% ~ 30%) 감소: 의미 있는 감소** <br> 경량화로 인해 모델 크기가 기존 대비 상당히 줄어들며, 메모리 사용량 감소의 실질적인 효과를 체감할 수 있는 수준입니다. 일반적인 애플리케이션에서 하드웨어 비용 절감과 함께 활용 가능성을 검토할 수 있습니다. <br> - **(30% ~ 40%) 감소: 눈에 띄는 감소** <br> 기존 대비 모델 크기 감소가 두드러져, 메모리 부담이 현저히 줄어드는 결과를 제공합니다. 특히, 고해상도 이미지를 생성하거나 GPU 메모리 제약이 있는 환경에서도 안정적으로 동작할 가능성이 높습니다. <br> - **(40% ~ 50%) 감소: 크게 감소** <br> 메모리 절감 효과가 매우 높아, 대규모 데이터 처리 및 저사양 하드웨어에서도 효과적으로 활용 가능합니다. 이는 경량화 기술의 최적화 성과로 간주될 수 있으며, 실제 애플리케이션에서 큰 메리트를 제공합니다. <br><br>  **3. 평가 방식** <br><br> 모델 크기 평가 방식은 weight 파라미터가 차지하는 전체 메모리 크기를 정량적으로 분석하여 모델 경량화 효과를 검증하기 위해 설계되었습니다. 이 과정은 다음 단계를 포함합니다: <br><br> **a) 파라미터 로드** <br> 모델 체크포인트 파일(`ckpt_path`)을 로드하여, 모델에 저장된 모든 weight 파라미터를 읽어옵니다. <br><br> **b) 파라미터 개수와 용량 계산** <br> 각 파라미터 텐서의 총 개수(`numel`)와 자료형별 단위 크기(`element_size`)를 곱하여 개별 weight가 차지하는 메모리 용량(바이트 단위)을 계산합니다. 이를 모든 파라미터에 대해 합산하여 모델이 차지하는 전체 메모리 크기를 산출합니다. <br><br> **c) 자료형별 분석** <br> 각 파라미터의 자료형(`dtype`)을 분류하고, 자료형별 파라미터 개수를 기록합니다. 이를 통해 모델 파라미터의 자료형 분포를 확인하고, 자료형 최적화 가능성을 탐색할 수 있습니다. <br><br> **d) 결과 도출** <br> - 전체 weight 파라미터의 개수 <br> - 모델이 차지하는 총 메모리 용량(MB 단위) <br> - 자료형별 파라미터 개수와 분포 <br><br> 이 모든 결과를 요약 출력하여 모델 크기 평가 결과를 정리합니다.|
|(3) 평가 방식B - 이미지 품질 저하(FID) | **1. 평가 항목 설명** <br><br> ***a)이미지 품질 저하*** <br> 이미지 품질 저하는 Diffusion Model에서 생성된 이미지가 실제 데이터와 비교했을 때 시각적 또는 통계적으로 열등한 특성을 보이는 상태를 의미합니다. 이는 생성된 이미지가 원본 데이터의 특징을 제대로 반영하지 못하거나, 데이터 분포가 일치하지 않을 때 발생합니다. 이미지 품질 저하를 정량적으로 평가하는 것은 모델의 성능을 검증하는 데 핵심적인 과정입니다. 이를 위해 Fréchet Inception Distance(FID)와 같은 지표가 사용됩니다. <br><br> ***b)FID(Fréchet Inception Distance)*** <br> 이미지 품질 평가 시 사용되는 평가 지표인 FID는 생성된 이미지와 실제 데이터 간의 품질 차이를 수치화하는 대표적인 지표로, 두 데이터 분포 간의 Fréchet 거리를 계산하여 이미지 품질을 평가합니다. <br> FID 값이 작을수록 생성된 이미지가 실제 데이터와 유사하다는 것을 의미하며, 반대로 값이 클수록 생성된 이미지가 실제 데이터와 크게 다르다는 것을 나타냅니다. <br> FID는 **Inception 네트워크**를 사용하여 이미지 데이터를 특징 공간(feature space)으로 매핑한 후, 해당 특징 분포의 평균(μ)과 공분산(Σ)을 기반으로 생성 이미지와 실제 이미지 간의 차이를 측정합니다. <br> FID는 다음의 수식으로 정의됩니다:<br><img width="719" alt="Screenshot 2024-12-12 at 8 07 03 PM" src="https://github.com/user-attachments/assets/38d0966d-1e5d-44c7-bab0-4fad1e64686b" /><br>여기서,<br> - $\mu_{r}$ , $\sum{r}$, : 실제 데이터(feature space)의 평균과 공분산 <br> - $\mu_{g}$ , $\sum{g}$: 생성된 데이터(feature space)의 평균과 공분산 <br> - $T_r$: 행렬의 대각합(trace) <br> 을 나타냅니다. <br> 첫 번째 항 $∣∣μr−μg∣∣2||\mu_r - \mu_g||^2$ 은 실제 데이터와 생성된 데이터의 평균 차이를 나타냅니다. <br> 두 번째 항 $Tr(Σr+Σg−2(ΣrΣg)1/2)Tr(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})$ 은 두 데이터의 공분산 행렬 차이를 반영하여 분포 모양의 차이를 평가합니다. <br> 이러한 특성을 통해 FID는 단순히 시각적인 차이뿐 아니라, 분포 전체의 일치를 고려하여 이미지 품질을 평가할 수 있는 신뢰도 높은 지표로 활용됩니다. 따라서, FID 값은 모델이 생성한 이미지의 품질 변화를 정량적으로 평가하고, 메모리 절감과 같은 최적화 기법이 이미지 품질에 미치는 영향을 분석하는 데 중요한 역할을 합니다. <br><br>  **2. 평가 기준** <br><br> - **22.7 ≤ FID < 23.0: 매우 우수** <br> 양자화에 따른 이미지 품질 손실이 거의 없으며, 품질이 기존 모델과 유사하거나 약간의 개선이 이루어진 것으로 평가됩니다. <br> - **23.0 ≤ FID < 23.5: 우수** <br> 약간의 품질 손실이 있지만, 여전히 이미지 품질이 높은 수준을 유지합니다. 실질적인 애플리케이션에 영향을 미치지 않는 수준으로 평가됩니다. <br> - **23.5 ≤ FID < 24.0: 보통** <br> 양자화로 인해 이미지 품질 손실이 눈에 띄게 발생하였지만, 여전히 수용 가능한 수준입니다. 특정 애플리케이션에서는 약간의 성능 저하가 있을 수 있습니다. <br> - **FID ≥ 24.0: 품질 저하** <br> 이미지 품질이 양자화로 인해 크게 저하되었음을 나타냅니다. 실질적인 사용에서 부정적인 영향을 미칠 가능성이 높습니다. |
|(4) 평가 내용/결과 |  |

<br>

# Conclusion
| 항목 | 내용 |
|:---  |---  |
|(1) 결론(Conclusion)| 본 연구는 Diffusion Model의 경량화를 위해 Fisher 정보를 활용한 레이어별 중요도 분석과 차등 양자화 기법을 제안하였습니다. 실험 결과, 레이어별 중요도에 따라 양자화 임곗값을 차등 적용하는 방식이 기존의 균일 양자화 방식에 비해 모델 크기 감소와 이미지 품질 향상에 더 효과적임을 입증하였습니다. 특히, 레이어 그룹별 임곗값 설정 실험에서는 모델 크기를 49.4% 줄이면서도 FID를 5% 개선하였으며, 이는 동일한 메모리 절감 수준에서도 더 우수한 이미지 품질을 제공하는 결과를 보여주었습니다. |
|(2) 의의(Implications) | 제안된 기법은 단순히 모델 크기 감소에 그치지 않고, 모델의 성능을 유지하거나 향상시킬 수 있는 가능성을 제시하였습니다. 이는 Diffusion Model의 경량화와 이미지 품질 간 균형을 이루는 데 실질적으로 기여할 수 있음을 시사합니다. 또한, 차등 양자화 방식은 Diffusion Model뿐만 아니라 유사한 구조를 가진 다른 대규모 딥러닝 모델에도 적용 가능성이 높아, 다양한 연구 및 실무 환경에서 활용될 수 있는 실용적이고 확장 가능한 방법론으로 평가될 수 있습니다. |
