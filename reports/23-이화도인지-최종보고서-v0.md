# Team-Info
| (1) 과제명 | Quantization based on Layer-wise Activation Analysis in Stable Diffusion Models
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 23-이화도인지 |
| (3) 팀 구성원 | 김도은 (2076035): 리더, *연구 및 논문 작성* <br> 박인애 (2171088): 팀원, *연구 및 논문 작성* <br> 변지은 (2076193) : 팀원, *연구 및 논문 작성*			 |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 팀 멘토 | 박준석 멘토님 / 삼성전자 / 수석 연구원 |
| (6) 과제 분류 | 연구 과제 |
| (6) 과제 키워드 | Diffusion model, Quantization, XAI  |
| (7) 과제 내용 요약 | 본 연구는 diffusion model이 timestep마다 서로 다른 layer를 활성화된다는 가설을 기반으로 진행되었습니다. MNIST 데이터셋을 사용하여 기본 diffusion 모델인 DDPM을 1,000 timestep 동안 학습시키고, 각 timestep에서 활성화된 layer를 분석하기 위해 Fisher information 값을 추출하여 활성화 양상을 평가합니다.<br><br>연구의 주요 목표는 diffusion model의 높은 inference time 문제를 개선하는 것입니다. 이를 위해 U-Net 구조에 quantization을 도입하여 연산 속도를 단축하고자 하며, Fisher information 분석 결과를 바탕으로 timestep별 활성화된 layer에 집중적으로 양자화를 적용하는 방식으로 문제를 해결할 계획입니다. 먼저 U-net을 6개 layer로 구분한 후에 각 파트별로 fisher information value 로 timestep마다 활성화되는 layer 및 layer 내의 weight 를 파악합니다. 이와 함께, 정량적 비교를 위해 log scale과 minmax 정규화 기법을 활용하여 정확한 분석을 수행했습니다. 연구 결과, 각 layer의 앞부분 weight가 전반적으로 큰 기여도를 가지며, timestep에 따른 weight 분포의 변화를 살펴본 결과, 초기 timestep에서는 layer의 앞부분 weight 기여도가 높고, 후반 timestep에서는 layer의 뒷부분 weight 기여도가 높아지는 경향을 발견하였습니다. 기존의 전체 layer 동일하게 quantization을 적용하는 방식이 아닌 layer 별로 맞춤형 quantization을 적용함으로써 모델의 속도를 높이되 quantization으로 인한 손실을 최소화하는 성과를 목표로 합니다.<br><br>Quantization 과정에서는 float형 비트 수 감소와 int형 변환을 통해 연산 효율성을 개선합니다. 본 연구는 diffusion model에 XAI 기법을 적용한 새로운 분석 방법을 제시하며, 제안된 quantization 기법이 inference 속도 향상에 기여할 것으로 기대됩니다.|
| (8) 주요 Link | 과제 GIT Address: https://github.com/Ewha-DoInJi/growth-research <br> 과제 보고서: https://github.com/Ewha-DoInJi/growth-research/blob/main/reports/23-이화도인지-1차보고서-v1.md|
| (10) 기타 |  |
<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | Diffusion Model은 DALL-E 3와 뤼튼과 같은 이미지 생성형 AI에 활용되고 있으며, 최근 주목받고 있는 모델입니다. 이 모델은 고품질의 다양한 이미지를 생성할 수 있다는 장점을 가지며, timestep마다 노이즈를 제거하는 과정을 반복하여 이미지를 생성하는 방식을 채택하고 있습니다. 이러한 샘플링 방식 덕분에 품질 높은 이미지를 다양하게 생성할 수 있지만, 대규모 파라미터로 인한 연산 복잡성, 느린 추론 속도, 높은 메모리 요구량이라는 기술적 한계를 가지고 있습니다. <br> 이 중 저희는 **높은 메모리 요구량**을 본 연구의 문제 정의로 선정하였습니다. Diffusion Model은 이미지 생성 과정에서 각 단계별로 중간 결과를 저장하고 업데이트해야 합니다. 특히, 고해상도 이미지 생성 시 중간 값을 메모리에 유지해야 하므로, 처리해야 할 데이터의 양이 증가하고 메모리 사용량이 급격히 늘어납니다. 이로 인해 GPU 메모리에 대한 의존도가 높아지고, 비용 증가, 메모리 초과 오류와 같은 문제가 빈번히 발생하여 실용성을 저해하고 있습니다. <br> 예를 들어, NeurIPS 2023에 게재된 *Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models* 논문에서도 Diffusion Model의 높은 GPU 메모리 요구량을 주요 문제로 지적한 바 있습니다. <br> 이러한 기술적 배경을 바탕으로, Diffusion Model의 메모리 사용량을 줄이고 효율성을 개선하는 연구는 중요한 주제로 떠오르고 있습니다. |
| (2) 기존 연구와의 비교 | Diffusion 모델에 Quantization을 적용하여 추론 속도를 향상시키는 기존 연구는 다음과 같습니다. 선행 연구 논문은 지도교수님의 추천과 해외 Top-tier 학회 논문을 기준으로 선정되었습니다. <br><br> 1. [Q-Diffusion: Quantizing Diffusion Models (ICCV 2023)](https://arxiv.org/abs/2302.04304) <br> 2. [PTQD: Accurate Post-Training Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2305.10657) <br> 3. [Temporal Dynamic Quantization for Diffusion Models (NeurIPS 2023)](https://arxiv.org/abs/2306.02316) <br><br> 위의 세 논문은 모두 재학습이 필요 없는 Post-Training Quantization (PTQ) 방식을 사용하여 Diffusion Model의 다중 timestep 특성에 최적화된 양자화 기법을 제시하고 있습니다. Quantization 과정에서 발생하는 오류 축적 문제는 노이즈 관리 및 분산 조정 등의 방법을 통해 해결하고 있으며, 모델 성능은 FID(Frechet Inception Distance) 점수, 메모리 요구량, 추론 속도 등으로 평가되었습니다. <br> 실험 결과, 양자화를 적용해서 대체로 메모리 요구량은 많이 줄었지만 모델 내 가중치의 상대적 중요성을 고려하지 않고 균일하게 양자화를 적용하여 이미지 생성 품질의 저하의 가능성이 확인되었습니다. <br> 이에 따라, 모델의 메모리 요구량을 효과적으로 줄일 수 있다는 점에서 양자화 기법을 채택하였으나, 동시에 Fisher Information Matrix 기법을 도입하여 layer별로 차등 양자화를 적용함으로써 기존 연구와의 차별성을 두고 이미지 생성 품질 저하를 최소화하고자 하였습니다. |
| (3) 제안 내용 | 본 연구의 목표는 Diffusion Model의 메모리 요구량를 개선하면서도 이미지 품질 저하를 최소화하는 데에 있습니다. 모델의 메모리 요구량을 줄이기 위해 흔히 사용되는 방법 중 하나는 양자화입니다. 그러나 양자화는 필연적으로 정보 손실을 초래하여 이미지 품질 저하를 야기할 수 있습니다. 이를 해결하기 위하여, 본 연구는 모델 전체에 일률적으로 양자화를 적용하는 대신, 이미지 품질에 상대적으로 낮은 기여도를 보이는 부분에는 보다 강하게 양자화를 적용하고, 이미지 품질에 높은 기여도를 보이는 부분에는 양자화 강도를 줄이는 접근법을 제안합니다. 따라서 본 연구는 이러한 차별화된 양자화 적용 방식을 통해 정보 손실을 최소화함으로써 추론 속도의 향상과 동시에 이미지 품질 저하를 최소화할 수 있을 것이라는 가설에 착안하여 연구를 진행하였습니다. <br> 본 연구는 Diffusion Model이 이미지를 생성하는 과정에서 layer별 활성화 정도가 다를 것이라는 가설을 바탕으로 진행되었습니다. 이를 확인하기 위해 Fisher Information Matrix를 활용하여 이미지 생성 과정에서의 layer별 기여도를 분석하였습니다. 레이어별 기여도 분석 결과를 기반으로 가중치의 Fisher 값에 대해 threshold를 설정하였으며, threshold 값보다 작은 Fisher 값을 가지는 가중치의 경우에만 선택적으로 양자화를 적용하는 방식을 도입하였습니다. 이를 통해 메모리 요구량 개선과 이미지 품질 유지 사이의 최적점을 도출하고자 하였습니다. |
| (4) 기대효과 및 의의 | 제안된 방법을 통해 다음과 같은 효과를 기대할 수 있습니다: <br> 1. 메모리 요구량 개선: 이미지 생성 과정에서의 Fisher Information 분석을 통해 기여도가 낮은 가중치에 양자화(값을 더 적은 비트로 표현)를 적용함으로써 전체적인 메모리 사용량을 감소시킬 수 있습니다. <br> 2. 이미지 품질 저하 최소화: 중요한 가중치의 정밀도를 보존함으로써 이미지 품질 저하를 최소화하는 것을 기대할 수 있습니다. |
| (5) 주요 기능 리스트 | DDPM, Weight Magnitude Map, Fisher Information Matrix, Quantization |

<br>
 
# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | **[요구사항1] 메모리 효율성 개선** <br> Diffusion Model에 레이어 적응형 양자화 기법을 도입하여 이미지 생성 과정의 메모리 사용량을 감소시킵니다. <br><br> **[요구사항2] 이미지 품질 보존** <br> 레이어별 기여도 분석을 통해 이미지 생성 과정에서 각 레이어의 중요도를 분석하고, 이를 바탕으로 차등 양자화를 적용하여 이미지 품질 저하를 최소화합니다.|
| (2) 전체 시스템 구성 | ![Pipeline](https://github.com/user-attachments/assets/35301f94-ead7-4ba4-a06b-7bf44d852647) <br> - **[1] Layer-wise Analysis**: Diffusion Model 의 레이어별 Fisher Information 분석 단계 <br> - **[2] Quantization**: 레이어 분석 결과에 따른 차등 양자화 적용 단계 <br><br> 본 연구는 간단한 DDPM 모델을 기반으로 구축된 U-Net을 MNIST 데이터셋에서 1000개의 timestep으로 학습시킨 후, 이를 대상으로 양자화 및 레이어 기여도 분석을 수행합니다. 연구는 크게 두 가지 주요 단계로 이루어집니다. <br><br><br> **[1] Layer-wise Analysis** <br><br> <img src="https://github.com/user-attachments/assets/eff9f21a-b80d-47e6-9df2-991ebd1ae817" alt="Eq1" style="width:200px; height:auto;"> &nbsp;&nbsp;(1) &nbsp;&nbsp;&nbsp;&nbsp; <img src="https://github.com/user-attachments/assets/a00e62e0-5b47-444d-a220-449e0347324c" alt="Eq2" style="width:200px; height:auto;"> &nbsp;&nbsp; (2) <br> Fisher Information은 특정 모델 가중치가 출력에 미치는 영향을 정량적으로 평가하는 척도로, 가중치의 중요도를 객관적으로 측정할 수 있습니다. Fisher 값이 높을수록 해당 가중치가 모델의 전반적인 성능에 더욱 중요한 기여를 한다는 것을 의미합니다. 본 연구에서는 먼저 손실 계산 단계에서 모델 출력과 목표값(ground truth) 간의 차이를 계산한 후, 이를 가중치에 대해 미분하여 Fisher 값을 산출하고(1), 이를 각 타임스텝과 레이어별로 저장하였습니다. 또한, 최대값을 기준으로 Fisher 값을 정규화함으로써 각 레이어와 타임스텝의 상대적 중요도를 용이하게 비교할 수 있게 하였습니다(2). <br><br> **[2] Quantization** <br> Fisher 값에 대한 분석 결과를 바탕으로 양자화 실험을 세 가지 주요 접근법으로 나누어 수행하였습니다. 모든 실험에서 FP32 자료형을 FP16으로 변환하는 양자화 방식으로 일관되게 적용하였으며, 성능 평가는 Fréchet Inception Distance(FID)와 모델 메모리 크기를 주요 지표로 활용하였습니다. FID 는 실제 이미지 5,000개와 샘플링 이미지 5,000개를 기반으로 계산되며, 낮은 값일수록 생성 이미지의품질이 우수함을 의미합니다. |
| (3) 주요엔진 및 기능 설계 | MNIST 데이터셋으로 훈련된 Diffusion Model이 이미지를 생성하는 과정에서, Fisher Information을 통해 레이어와 가중치의 중요도를 분석하고, 분석한 결과를 바탕으로 양자화를 적용하여 모델의 메모리 사용량을 절감하면서도 성능 저하를 최소화하는 것을 목표로 합니다. <br><br> **1. 사용된 주요 라이브러리** <br><br> - **PyTorch**: 모델 생성, 학습, 최적화, 텐서 연산 등 전체적인 딥러닝 파이프라인 구현합니다. <br> - **PyTorch**: 모델 생성, 학습, 최적화 및 텐서 연산 수행. <br> - **torchvision**: MNIST 데이터셋 다운로드 및 전처리. <br> - **einops**: 텐서 변환으로 모델 어텐션 및 U-Net 레이어의 효율적인 데이터 조작 지원. <br> - **tqdm**: 학습 및 이미지 생성 과정에서 진행 상황 시각화. <br> - **matplotlib**: Fisher Information 분석 및 모델 결과 시각화. <br><br>  **2. 주요 모듈 설명 및 역할**<br><br> ***a) 데이터 준비 및 전처리*** <br> - **역할**: MNIST 데이터셋 로드 및 텐서로 변환하여 모델 학습 및 평가에 적합하게 처리. <br> - **구현**: `datasets.MNIST`와 `DataLoader`를 사용하여 배치 단위로 데이터를 로드하며, `transforms.ToTensor()`로 정규화된 텐서를 생성. <br><br> ***b) 모델 구성 모듈 (U-Net)*** <br> **i) 임베딩 모듈** <br> - **역할**: 각 timestep에 해당하는 시간 정보를 벡터로 변환하여 모델에 제공. <br> - **특징**: Sinusoidal 함수를 사용하여 시간 정보를 임베딩. <br> **ii) Residual 모듈** <br> - **역할**: 잔차 연결로 정보 손실 방지 및 학습 안정화. <br> - **구성 요소**: GroupNorm, Conv2D, Dropout. <br> **iii) 어탠션 모듈(Attention)** <br> - **역할**: 특정 레이어에 어텐션 메커니즘을 적용하여 중요도를 조정. <br> - **특징**: 다중 헤드 어텐션 사용. <br> **iv). U-Net 레이어(U-Net Layer)** <br> - **역할**: 업샘플링, 다운샘플링 및 어텐션 적용. <br> - **특징**: Residual 블록과 업/다운샘플링 Conv 레이어로 구성. <br> **v) 전체 U-Net 모델(U-Net)** <br> - **역할**: 인코더-디코더 구조로 노이즈를 제거하고 이미지를 생성. <br> - **특징**: 6개의 레이어로 구성된 멀티스케일 구조. <br><br> ***c) Diffusion 과정 및 스케줄러*** <br> - **DDPM_Scheduler**: timestep마다 노이즈를 추가/제거하기 위한 α, β 파라미터를 설정. <br> - **훈련 함수 (train)**: 각 epoch 동안 손실 계산 및 EMA(Exponential Moving Average)를 사용해 학습 안정성을 유지. <br><br> ***d) Fisher Information 계산 및 양자화*** <br> i) **Fisher Information 계산**: 각 timestep에서 각 레이어의 가중치 중요도를 평가. <br> ii) **가중치 크기 분석**: 각 레이어의 Fisher Information을 분석하여 모델의 기여도를 시각화. <br> iii) **양자화 적용**: 특정 Threshold를 기준으로 중요도가 낮은 가중치를 파이토치의 half 함수로 양자화(FP16)하여 메모리 사용량 감소 및 효율성 향상. <br><br> ***e) 이미지 생성 및 평가*** <br> - **Inference**: 노이즈 텐서에서 점진적으로 노이즈를 제거하여 최종 이미지 생성. <br> - **FID 점수 계산**: 실제 이미지와 생성된 이미지 간의 차이를 측정하여 성능 평가. <br> - **시각화**: Fisher Information 및 생성된 이미지를 시각화하여 분석 결과를 정리. <br><br>  **3. 주요 기능 및 데이터 흐름**<br><br> ***a) 훈련 단계*** <br> - 데이터 준비 → 모델 학습(train) → 노이즈 스케줄러를 통한 점진적 학습 → Fisher Information 계산. <br><br> ***b) Fisher Information 분석 및 양자화*** <br> - timestep별 개별 레이어의 Fisher Information을 계산하고, 중요도가 낮은 가중치를 파이토치 라이브러리의 half 함수로 FP32→FP16 으로 양자화하여 모델 효율성 향상. <br><br> ***c) Inference 및 성능 평가*** <br> - 양자화된 모델을 사용해 이미지를 생성하고, FID score 및 모델의 크기로 성능을 평가. <br> - 생성된 이미지와 분석 결과를 시각화. |
| (4) 주요 기능의 구현 | 본 연구에서 사용된 Diffusion Model은 [다음의 글](https://towardsdatascience.com/diffusion-model-from-scratch-in-pytorch-ddpm-9d9760528946)을 참고하여 구현하였습니다. 해당 Simple Diffusion Model은 MNIST 데이터셋에서 수행되었으며, 6개 레이어의 U-Net 아키텍처로 구현되었습니다. 모델은 1,000 타임스텝을 기준으로 학습되었습니다. <br><br> **[1] Layer-wise 실험 결과** <br> <img width="300" alt="Fisher Information Map per Layers (w:o log scale)" src="https://github.com/user-attachments/assets/de16eda0-e1fc-40d2-896f-6d0925f718ca"> &nbsp; <img width="300" alt="Fisher Information Map per Layers (w: log scale)" src="https://github.com/user-attachments/assets/e05c5093-bbc8-47f5-adcc-22a3898cec2a"><br>*(좌) 타임스텝에 따른 레이어별 Fisher 값 (Log scale 미적용) / (우) 타임스텝에 따른 레이어별 Fisher 값 (Log scale 적용)*<br><br>레이어별 Fisher Information 값을 분석한 결과, 레이어1과 2는 현저히 높은 기여도를 나타낸 반면, 레이어 3, 4, 5, 6은 상대적으로 낮은 기여도를 보였습니다. 또한, 타임스텝이 진행되어 최종 이미지에 근접할수록 Fisher 값이 증가하는 경향을 관찰할 수 있었습니다. 이를 바탕으로 본 연구는 마지막 타임스텝의 Fisher 값을 기준으로 차등 양자화 전략을 설계하였습니다. <br><br> **[2] Quantization 실험 결과** <br> **1. 단일 임곗값 설정 **<br> Fisher 값 분석 결과를 바탕으로, 모델 전체 가중치에 적용될 단일 임계값을 설정하고, 이 임계값 미만의 Fisher 값을 갖는 가중치에 대하여 양자화를 적용하였습니다. <br><br> **2.레이어 그룹별 임곗값 설정** <br> Fisher Information 분석 결과에 따르면, 레이어 1 과 2 는 최대값 1e5 수준의 매우 높은 기여도를 보였으며, 레이어 3, 4, 5 는 1e-1, 레이어 6 은 1e 수준으로 상대적으 로 낮은 기여도를 나타냈습니다. 이러한 분석을 바탕으로 레이어 1 과 2 를 단일 그룹으로 묶고, 나머지 레이어를 하나의 그룹으로 처리한 설정(레이어 12 / 3456)과 레이어 1과 2를 하나의 그룹으로 유지하면서 나머지 레이어를 더욱 세분화한 설정(레이어 12 / 345 / 6)으로 나누어 실험을 진행하였습니다. <br><br> **3.레이어별 임곗값 설정** <br> 레이어별 임곗값 설정을 위해 임곗값 비율을 도입하였습니다. 임곗값 비율 p 가 주어졌을 때, 해당 레이어의 피셔 값 분포에서 (1-p)×100 백분위수에 해당하는 값을 임곗값으로 선택합니다. 예를 들어, 임곗값 비율이 0.3 인 경우, 피셔 값 분포의 상위 30%에 해당하는 값이 해당 레이어의 임곗값으로 채택됩니다. 임계값 비율을 0.1부터 0.5까지 0.05씩 증가시키면서 실험한 결과는 다음과 같습니다. <br> <img src="https://github.com/user-attachments/assets/9558b7d0-a09e-47c7-80c2-50170f2802bd" alt="Eq2" style="width:400px; height:auto;">|
| (5) 기타 | 11월 내에 진행되는 학회 및 공모전을 탐색 중에 있으며, 만약 있다면 참가할 예정입니다. |

<br>

# Evaluation
| 항목 | 내용 |
|:---  |---  |
|(1) 평가 항목 |  |
|(2) 평가 기준 |  |
|(3) 평가 방식 |  |
|(4) 평가 내용/결과 |  |

<br>

# Conclusion
| 항목 | 내용 |
|:---  |---  |
|(1) 결론(Conclusion)| 본 연구는 확산 모델의 경량화를 위해 피셔 값을 활용한 레이어별 중요도 분석과 이를 기반으로 한 차등 양자화 기법을 제안하였습니다. 기존의 전체 모델에 동일한 임곗값을 적용하는 단순 양자화 방식과 비교했을 때, 레이어별 중요도에 따라 임곗값을 차등 적용하는 접근법이 모델 크기 감소와 이미지 품질 향상에 더 효과적임을 실험적으로 검증하였습니다. <br> 레이어별 임곗값 비율 설정 실험 결과, 임곗값 비율이 0.25 일 때 FID 가 전체 양자화 방식 대비 약 7% 개선되었으며, 모델 크기는 양자화 이전 대비 23.8% 감소하였습니다. 또한, 레이어 그룹별 임곗값 설정 방식은 FID 를 5% 향상시키는 동시에 모델 크기를 49.4% 줄이는 성과를 보였습니다. 특히, 단일 임곗값 모델과 비교했을 때, 동일한 수준의 메모리 절감에도 불구하고 FID 점수가 더 우수하게 나타났습니다. 이는 제안된 방식이 단순히 메모리 절감에만 효과적인 것이 아니라, 모델의 성능을 향상시킬 수 있는 잠재력을 가지고 있음을 시사합니다. <br> 결론적으로, 이 연구는 확산 모델 경량화와 이미지 품질 간의 균형을 이루는 데 효과적임을 보였으며, 차등 양자화의 실용성과 확장 가능성을 제시합니다. |
